
@misc{center_for_history_and_new_media_guia_????,
  title = {Guia de {{Inicia{\c c}{\~a}o R{\'a}pida}} Do {{Zotero}}},
  timestamp = {2017-06-14T00:08:37Z},
  url = {http://zotero.org/support/quick_start_guide},
  author = {{Center for History and New Media}},
  annote = {Bem-vindo ao Zotero!
Veja o Guia de Inicia{\c c}{\~a}o R{\'a}pida para aprender a recolher, gerir, citar e partilhar as suas fontes de investiga{\c c}{\~a}o.
Obrigado por instalar o Zotero.}
}

@book{shapiro_computer_2001,
  address = {Upper Saddle River, NJ},
  title = {Computer Vision},
  isbn = {978-0-13-030796-5},
  lccn = {TA1634 .S48 2001},
  timestamp = {2017-06-14T00:23:20Z},
  publisher = {{Prentice Hall}},
  author = {Shapiro, Linda G. and Stockman, George C.},
  year = {2001},
  keywords = {Computer vision},
  file = {cc-12.pdf:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\FNK4NZ23\\cc-12.pdf:application/pdf}
}

@misc{_about_????,
  title = {About {{FFmpeg}}},
  timestamp = {2017-06-14T12:18:09Z},
  urldate = {2017-06-14},
  url = {https://ffmpeg.org/about.html},
  file = {About FFmpeg:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MGWQHF79\\about.html:text/html}
}

@misc{_java_????,
  title = {Java - {{OpenCV}} ({{JavaCV}}) vs {{OpenCV}} ({{C}}/{{C}}++ Interfaces) - {{Stack Overflow}}},
  timestamp = {2017-06-14T12:19:54Z},
  urldate = {2017-06-14},
  url = {https://stackoverflow.com/questions/21207755/opencv-javacv-vs-opencv-c-c-interfaces},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\44PATV76\\opencv-javacv-vs-opencv-c-c-interfaces.html:text/html}
}

@misc{_javacpp:_2017,
  title = {Javacpp: {{The}} Missing Bridge between {{Java}} and Native {{C}}++},
  shorttitle = {Javacpp},
  timestamp = {2017-06-14T12:25:26Z},
  url = {https://github.com/bytedeco/javacpp},
  publisher = {{Bytedeco}},
  month = jun,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\38U22MA9\\javacpp.html:text/html}
}

@misc{_kinect_????,
  title = {Kinect and {{OpenNI}} \textemdash{} {{OpenCV}} 2.4.13.2 Documentation},
  timestamp = {2017-06-14T12:25:29Z},
  urldate = {2017-06-14},
  url = {http://docs.opencv.org/2.4.13.2/doc/user_guide/ug_kinect.html},
  file = {Kinect and OpenNI — OpenCV 2.4.13.2 documentation:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\J66UNKVF\\ug_kinect.html:text/html}
}

@misc{_javacpp-presets:_2017,
  title = {Javacpp-Presets: {{The}} Missing Bridge between {{Java}} and Native {{C}}++ Libraries},
  shorttitle = {Javacpp-Presets},
  timestamp = {2017-06-14T12:25:33Z},
  url = {https://github.com/bytedeco/javacpp-presets},
  publisher = {{Bytedeco}},
  month = jun,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\B9UUHMFU\\javacpp-presets.html:text/html}
}

@misc{opencv_about_2017,
  title = {About - {{OpenCV}} Library},
  timestamp = {2017-06-15T03:53:23Z},
  urldate = {2017-06-14},
  url = {http://opencv.org/about.html},
  author = {OpenCV},
  year = {2017},
  file = {About - OpenCV library:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PEKEEHPW\\about.html:text/html}
}

@misc{dahms_opencv_3_car_counting_cpp_2017,
  title = {{{OpenCV}}\_3\_{{Car}}\_{{Counting}}\_{{Cpp}}},
  timestamp = {2017-06-15T03:27:14Z},
  url = {https://github.com/MicrocontrollersAndMore/OpenCV_3_Car_Counting_Cpp},
  author = {Dahms, Chris},
  month = may,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RXBI7ZPR\\OpenCV_3_Car_Counting_Cpp.html:text/html}
}

@misc{_structural_????,
  title = {Structural {{Analysis}} and {{Shape Descriptors}} \textemdash{} {{OpenCV}} 3.0.0-Dev Documentation},
  timestamp = {2017-06-15T03:28:55Z},
  urldate = {2017-06-15},
  url = {http://docs.opencv.org/3.0-beta/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html},
  file = {Structural Analysis and Shape Descriptors — OpenCV 3.0.0-dev documentation:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PDFFP6EN\\structural_analysis_and_shape_descriptors.html:text/html}
}

@misc{dahms_contribute_2017,
  title = {Contribute to {{OpenCV}}\_3\_{{Car}}\_{{Counting}}\_{{Cpp}} Development by Creating an Account on {{GitHub}}},
  timestamp = {2017-06-15T03:57:09Z},
  url = {https://github.com/MicrocontrollersAndMore/OpenCV_3_Car_Counting_Cpp},
  author = {Dahms, Chris},
  month = may,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ZKBCEEM4\\OpenCV_3_Car_Counting_Cpp.html:text/html}
}

@misc{_blob_????,
  title = {Blob {{Detection Using OpenCV}} ( {{Python}}, {{C}}++ ) | {{Learn OpenCV}}},
  timestamp = {2017-06-16T12:52:42Z},
  urldate = {2017-06-16},
  url = {https://www.learnopencv.com/blob-detection-using-opencv-python-c/},
  file = {Blob Detection Using OpenCV ( Python, C++ ) | Learn OpenCV:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\Q6MSHU7K\\blob-detection-using-opencv-python-c.html:text/html}
}

@misc{opencv_opencv:_2017,
  title = {{{OpenCV}}: Cv::{{SimpleBlobDetector Class Reference}}},
  timestamp = {2017-06-16T12:58:38Z},
  urldate = {2017-06-16},
  url = {http://docs.opencv.org/trunk/d0/d7a/classcv_1_1SimpleBlobDetector.html},
  author = {OpenCV},
  year = {2017},
  file = {OpenCV\: cv\:\:SimpleBlobDetector Class Reference:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7DZVEGZJ\\classcv_1_1SimpleBlobDetector.html:text/html}
}

@inproceedings{badenas_applying_1998,
  title = {Applying Computer Vision Techniques to Traffic Monitoring Tasks},
  doi = {10.1007/3-540-64582-9_810},
  abstract = {This paper presents a method for tracking and segmenting vehicles in a traffic scene. The approach is based on a frame to frame segmentation followed by a tracking process. As opposed to usual segmentation methods, our method feedbacks segmentation with tracking information for improving results. Several facilities are provided for traffic monitoring such as vehicles trajectories surveillance, segmentation of vehicle shape, measuring the mean velocity of the traffic, counting the vehicles that are moving on the lanes of a road or a motorway, counting the vehicles that stop at a junction and detection of events such as a vehicle stops on a road or a possible accident.},
  language = {en},
  timestamp = {2017-06-17T20:31:26Z},
  urldate = {2017-06-17},
  url = {https://link.springer.com/chapter/10.1007/3-540-64582-9_810},
  booktitle = {Methodology and {{Tools}} in {{Knowledge}}-{{Based Systems}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Badenas, Jorge and Pla, Filiberto},
  month = jun,
  year = {1998},
  pages = {776--785},
  file = {Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\W9R2T8HX\\Badenas e Pla - 1998 - Applying computer vision techniques to traffic mon.pdf:application/pdf;Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\D5J6RFS6\\3-540-64582-9_810.html:text/html}
}

@misc{acm_ccs_2012,
  title = {{{CCS}} 2012},
  timestamp = {2017-06-18T15:02:24Z},
  urldate = {2017-06-18},
  url = {http://dl.acm.org/ccs/ccs_flat.cfm},
  author = {ACM},
  year = {2012},
  file = {CCS 2012:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\S3U3FCZE\\ccs_flat.html:text/html}
}

@misc{acm_2012_2012,
  title = {The 2012 {{ACM Computing Classification System}} \textemdash{} {{Association}} for {{Computing Machinery}}},
  timestamp = {2017-06-18T15:03:52Z},
  urldate = {2017-06-18},
  url = {http://www.acm.org/about/class/class/2012},
  author = {ACM},
  year = {2012},
  file = {The 2012 ACM Computing Classification System — Association for Computing Machinery:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7ATTAGFN\\2012.html:text/html}
}

@misc{huang_ballard_computer_vision_1996,
  title = {Ballard {{D}}. and {{Brown C}}. {{M}}. - {{Computer Vision}}},
  timestamp = {2017-06-18T15:27:04Z},
  urldate = {2017-06-18},
  url = {http://homepages.inf.ed.ac.uk/rbf/BOOKS/BANDB/Ballard__D._and_Brown__C._M.__1982__Computer_Vision.pdf},
  author = {Huang, T. S.},
  month = sep,
  year = {1996},
  file = {Ballard__D._and_Brown__C._M.__1982__Computer_Vision.pdf:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ZA2KWSFS\\Ballard__D._and_Brown__C._M.__1982__Computer_Vision.pdf:application/pdf}
}

@book{klette_computer_1998,
  title = {Computer {{Vision}}: {{Three}}-{{Dimensional Data}} from {{Images}}},
  isbn = {978-981-3083-71-4},
  shorttitle = {Computer {{Vision}}},
  abstract = {This book explores computer vision, describing the reconstruction of object surfaces and the analysis of distances between camera and objects. Fundamentals and algorithms are presented, including topics such as dynamic stereo analysis, shape from shading, photometric stereo analysis, and structural illumination. New research results in shape reconstruction and depth analysis are also included.},
  language = {en},
  timestamp = {2017-06-18T15:37:15Z},
  publisher = {{Springer Singapore}},
  author = {Klette, Reinhard and Schluns, Karsten and Koschan, Andreas},
  month = sep,
  year = {1998},
  note = {Google-Books-ID: qOJRAAAAMAAJ},
  keywords = {Computers / Computer Graphics,Computers / Computer Science,Computers / Information Technology,Computers / Optical Data Processing,Computers / Programming / General}
}

@misc{huang_computer_1996,
  title = {Computer {{Vision}} : {{Evolution And Promise}}},
  shorttitle = {Computer {{Vision}}},
  abstract = {Huang, T},
  timestamp = {2017-06-18T15:38:11Z},
  urldate = {2017-06-18},
  url = {http://cds.cern.ch/record/400313},
  journal = {CERN Document Server},
  author = {Huang, T.},
  year = {1996},
  file = {Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MCIUWN3J\\Huang - 1996 - Computer Vision  Evolution And Promise.pdf:application/pdf;Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\IZ4CBIUQ\\400313.html:text/html}
}

@article{stout_computer_1980,
  title = {Computer Vision and Robots},
  volume = {59},
  issn = {0032-9851},
  doi = {10.1049/tpe.1980.0060},
  timestamp = {2017-06-18T15:49:06Z},
  number = {4},
  journal = {Production Engineer},
  author = {Stout, K. J.},
  month = apr,
  year = {1980},
  pages = {9--},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\G4N5TECJ\\Stout - 1980 - Computer vision and robots.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\WXDAJ9X6\\4926470.html:text/html}
}

@article{l._baird_sight-i:_1978,
  title = {{{SIGHT}}-{{I}}: {{A Computer Vision System}} for {{Automated IC Chip Manufacture}}},
  volume = {8},
  issn = {0018-9472},
  shorttitle = {{{SIGHT}}-{{I}}},
  doi = {10.1109/TSMC.1978.4309913},
  timestamp = {2017-06-18T16:17:15Z},
  number = {2},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  author = {L. Baird, Michael},
  month = feb,
  year = {1978},
  keywords = {Application software,Assembly,Automatic testing,Computer aided manufacturing,Computer vision,Heat sinks,Laboratories,Manufacturing automation,Probes,Production systems},
  pages = {133--139},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\289HE2BC\\1978 - SIGHT-I A Computer Vision System for Automated IC.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\A9KDW7ZX\\4309913.html:text/html}
}

@article{binford_computer_1973-2,
  title = {Computer Vision},
  volume = {6},
  issn = {0018-9162},
  doi = {10.1109/MC.1973.6536714},
  abstract = {``Intelligent'' computers require knowledge of their environment, and the most effective means of acquiring such knowledge is by seeing. Vision opens a new realm of computer applications. Weather analysis from cloud maps and medical diagnosis from x-rays and blood cell counts are two of many high volume data processing tasks that require pictorial input. Man-machine communication will be facilitated if a person can directly show the computer a real object, rather than describe it symbolically. Designers, for example, could then easily obtain a computerized structural analysis of scale models.},
  timestamp = {2017-06-18T16:51:38Z},
  number = {5},
  journal = {Computer},
  author = {Binford, T. O. and Tenenbaum, J. M.},
  month = may,
  year = {1973},
  pages = {19--24},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\M42GBJQG\\6536714.html:text/html}
}

@inproceedings{ayache_medical_1998,
  title = {Medical Image Analysis a Challenge for Computer Vision Research},
  volume = {2},
  doi = {10.1109/ICPR.1998.711928},
  abstract = {Automating the analysis of multidimensional medical images is extremely promising to improve diagnosis and therapy quality of tomorrow's medical practice. This automation will require the solution of a number of challenging research problems, many of them being closely related to computer vision problems. The paper presents first the medical tasks that will benefit from automated medical image analysis. Then, it describes a selection of the associated research problems, with illustrations of recent results and advances},
  timestamp = {2017-06-18T16:57:26Z},
  booktitle = {Proceedings. {{Fourteenth International Conference}} on {{Pattern Recognition}} ({{Cat}}. {{No}}.{{98EX170}})},
  author = {Ayache, N.},
  month = aug,
  year = {1998},
  keywords = {Biomedical imaging,Computer vision,computer vision research,diagnosis,Image analysis,Image motion analysis,Image sequence analysis,Medical diagnostic imaging,medical image analysis,medical image processing,Medical simulation,Medical treatment,multidimensional medical images,Pathology,therapy quality,Ultrasonic imaging},
  pages = {1255--1256 vol.2},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RDWZTK6Q\\711928.html:text/html}
}

@article{buch_review_2011,
  title = {A {{Review}} of {{Computer Vision Techniques}} for the {{Analysis}} of {{Urban Traffic}}},
  volume = {12},
  issn = {1524-9050},
  doi = {10.1109/TITS.2011.2119372},
  abstract = {Automatic video analysis from urban surveillance cameras is a fast-emerging field based on computer vision techniques. We present here a comprehensive review of the state-of-the-art computer vision for traffic video with a critical analysis and an outlook to future research directions. This field is of increasing relevance for intelligent transport systems (ITSs). The decreasing hardware cost and, therefore, the increasing deployment of cameras have opened a wide application field for video analytics. Several monitoring objectives such as congestion, traffic rule violation, and vehicle interaction can be targeted using cameras that were typically originally installed for human operators. Systems for the detection and classification of vehicles on highways have successfully been using classical visual surveillance techniques such as background estimation and motion tracking for some time. The urban domain is more challenging with respect to traffic density, lower camera angles that lead to a high degree of occlusion, and the variety of road users. Methods from object categorization and 3-D modeling have inspired more advanced techniques to tackle these challenges. There is no commonly used data set or benchmark challenge, which makes the direct comparison of the proposed algorithms difficult. In addition, evaluation under challenging weather conditions (e.g., rain, fog, and darkness) would be desirable but is rarely performed. Future work should be directed toward robust combined detectors and classifiers for all road users, with a focus on realistic conditions during evaluation.},
  timestamp = {2017-06-18T17:28:30Z},
  number = {3},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  author = {Buch, N. and Velastin, S. A. and Orwell, J.},
  month = sep,
  year = {2011},
  keywords = {3D modeling,automatic video analysis,Cameras,Closed-circuit television (CCTV),Computer vision,computer vision techniques,intelligent transport systems,intersection monitoring,object categorization,Pixel,Roads,road traffic,road user counting,road users,solid modelling,Surveillance,traffic analysis,traffic information systems,traffic rule violation,urban surveillance cameras,urban traffic,urban traffic analysis,vehicle classification,vehicle detection,vehicle interaction,Vehicles,video surveillance,visual surveillance},
  pages = {920--939},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\M2M4FZK7\\Buch et al. - 2011 - A Review of Computer Vision Techniques for the Ana.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\DB5MKQPS\\5734852.html:text/html}
}

@article{dickinson_image_1984,
  title = {{{IMAGE PROCESSING APPLIED TO TRAFFIC}}, 1-{{A GENERAL REVIEW}}},
  volume = {25},
  issn = {0041-0683},
  timestamp = {2017-06-18T17:45:58Z},
  number = {1},
  urldate = {2017-06-18},
  url = {https://trid.trb.org/view.aspx?id=211436},
  journal = {Traffic Engineering \& Control},
  author = {Dickinson, K. W. and Waterfall, R. C.},
  month = jan,
  year = {1984},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\GVC6W3EE\\view.html:text/html}
}

@inproceedings{lira_computer-vision_2016,
  title = {A Computer-Vision Approach to Traffic Analysis over Intersections},
  doi = {10.1109/ITSC.2016.7795530},
  abstract = {In recent years, there has been an interest in detailed monitoring of road traffic, particularly in intersections, in order to obtain a statistical model of the flow of vehicles through them. These models aid in the optimization of traffic management and allow for smarter transportation systems. While conventional methods sensors at each of the intersections entrances/exits allow for counting, are limited in the sense that it is impossible to track a vehicle from origin to destination. A solution is presented using computer vision algorithms to footage obtained from drones floating over an intersection, in order to identify and track vehicles so that a statistical model may be extracted. This model is based on said association of an origin and a destination. The algorithm employs background subtraction and vehicle tracking with Kalman filters. The most significant challenge was how to compensate for camera movement. Based on the implementation which was developed, this the approach proved useful for tracking cars, buses, and trucks under some conditions. This paper is based upon research work done for a masters dissertation project.},
  timestamp = {2017-06-19T01:05:27Z},
  booktitle = {2016 {{IEEE}} 19th {{International Conference}} on {{Intelligent Transportation Systems}} ({{ITSC}})},
  author = {Lira, G. and Kokkinogenis, Z. and Rossetti, R. J. F. and Moura, D. C. and R{\'u}bio, T.},
  month = nov,
  year = {2016},
  keywords = {background subtraction,camera movement compensation,Cameras,computerised instrumentation,Computer vision,computer-vision approach,Feature extraction,Kalman filter,Kalman filters,master dissertation project,object tracking,optimisation,optimization,Roads,road traffic,road traffic management analysis,sensor,Sensors,smart transportation system,statistical analysis,statistical model,Tracking,Vehicles,vehicle tracking},
  pages = {47--53},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ZCA2EBNM\\Lira et al. - 2016 - A computer-vision approach to traffic analysis ove.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\SGBBPJQX\\7795530.html:text/html}
}

@inproceedings{hashmi_analysis_2012,
  title = {Analysis and Monitoring of a High Density Traffic Flow at {{T}}-Intersection Using Statistical Computer Vision Based Approach},
  doi = {10.1109/ISDA.2012.6416512},
  abstract = {A reliable traffic flow monitoring and traffic analysis approach using computer vision techniques has been proposed in this paper. The exponential increase in traffic density at urban intersections in the past few decades has raised precious and challenging demands to computer vision algorithms and technological solutions. The focus of this paper is to suggest a statistical based approach to determine the traffic parameters at heavily crowded urban intersections. The algorithm in addition to accurate tracking and counting of freeway traffic also offers high efficiency for determining vehicle count at a high traffic density T-intersection. The system uses Intel Open CV library for image processing. The implementation of algorithm is done using C++. The real time video sequence is obtained from a stationary camera placed atop a high building overlooking the particular T intersection. This paper suggests a dynamic method where each vehicle at a T intersection is passed through a number of detection zones and the final count of vehicles is derived from a statistical equation.},
  timestamp = {2017-06-19T01:08:07Z},
  booktitle = {2012 12th {{International Conference}} on {{Intelligent Systems Design}} and {{Applications}} ({{ISDA}})},
  author = {Hashmi, M. F. and Keskar, A. G.},
  month = nov,
  year = {2012},
  keywords = {Algorithm design and analysis,C++,C++ language,Computer vision,Detection zone,detection zones,freeway traffic,Heuristic algorithms,high density traffic flow analysis,high density traffic flow monitoring,image processing,image sensors,image sequences,Intel Open CV library,Monitoring,Open CV,public domain software,Real-time systems,real time video sequence,stationary camera,statistical analysis,statistical computer vision based approach,statistical equation,T-intersection,traffic engineering computing,traffic parameter determination,urban intersections,vehicle count determination,vehicle detection,Vehicles,video signal processing},
  pages = {52--57},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RWJN76SB\\Hashmi e Keskar - 2012 - Analysis and monitoring of a high density traffic .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\BC2XVBF4\\6416512.html:text/html}
}

@incollection{loce_traffic_2017,
  title = {Traffic {{Flow Analysis}}},
  isbn = {978-1-118-97166-6},
  abstract = {This chapter discusses traffic flow analysis in the context of technologies for intelligent transportation systems (ITS) from three important perspectives. First, we look at traffic flow from a transport engineering perspective so as to set the context in terms of the application domain. Second, we consider how flow could be observed using computer vision means and provide an overall review of relevant current research in the field. Third, we illustrate how a practical computer vision system can measure some of the variables required by traffic engineers. Last, we highlight some of the challenges posed by traffic monitoring especially in developing countries, where the density of traffic is growing at a faster rate.},
  timestamp = {2017-06-19T01:13:49Z},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7906282},
  booktitle = {Computer {{Vision}} and {{Imaging}} in {{Intelligent Transportation Systems}}},
  publisher = {{Wiley-IEEE Press}},
  author = {Loce, Robert P. and Bala, Raja and Trivedi, Mohan},
  year = {2017},
  pages = {432--},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\H29A9Z8P\\articleDetails.html:text/html},
  doi = {10.1002/9781118971666.ch6}
}

@incollection{loce_detection_2017,
  title = {Detection of {{Moving Violations}}},
  isbn = {978-1-118-97166-6},
  abstract = {Law enforcement agencies and municipalities are increasing the deployment of camera\textquestiondown\textquestiondown\textquestiondown{}based roadway monitoring systems with the goal of reducing unsafe driving behavior. While some camera\textquestiondown\textquestiondown\textquestiondown{}based systems use the acquired images and videos solely for evidentiary purposes, there is increasing use of computer vision techniques for automating the detection of violations. The most commonly monitored violations include speeding, running red lights or stop signs, wrong\textquestiondown\textquestiondown\textquestiondown{}way driving, and making illegal turns. Most traffic law enforcement applications in roadway computer vision systems involve analyzing well\textquestiondown\textquestiondown\textquestiondown{}defined and acceptable trajectories and speeds, which leads to clearly defined rules and detections. In some cases, the detections are binary, such as in red light enforcement (stopped or not). Other applications require increased accuracy and precision, such as detecting speed violations and applying a fine according to the estimated vehicle speed. There are other deployed applications where the violation involves less definitive criteria, such as reckless driving. This chapter presents various applications, giving the motivation, system requirements, methodology, and effectiveness. The more common applications of speed and stop light are described in detail, while the less common ones are briefly noted.},
  timestamp = {2017-06-19T01:13:58Z},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7906251},
  booktitle = {Computer {{Vision}} and {{Imaging}} in {{Intelligent Transportation Systems}}},
  publisher = {{Wiley-IEEE Press}},
  author = {Loce, Robert P. and Bala, Raja and Trivedi, Mohan},
  year = {2017},
  pages = {432--},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7J7I8Q3K\\articleDetails.html:text/html},
  doi = {10.1002/9781118971666.ch5}
}

@inproceedings{soendoro_traffic_2011,
  title = {Traffic Sign Recognition with {{Color}}-Based {{Method}}, Shape-Arc Estimation and {{SVM}}},
  doi = {10.1109/ICEEI.2011.6021584},
  abstract = {Traffic sign recognition is studied as one of the modern assistance in driving. The main purpose of it is to help driver on realizing traffic sign around the car by using computer vision enhanced to the car. In this paper, a combination method of Color-based Method and SVM is presented to do the traffic sign recognition. Color-based Method with CIELab + hue is chosen because it gives good result on localizing traffic signs. It is first used to preprocess the image to binary image. The binary image is then processed with canny to give more accurate result on detecting traffic signs. To get the traffic sign shape, the preprocessed image is checked by using Ramer-Douglas-Peucker algorithm, this algorithm will approximate each closed object shape in the preprocessed image. Detecting closed object make it unable to detect occluded and attached road signs. In order to detect occluded and attached signs, the proposed method will use two phase of detection by estimating the shape of the arc or later called the shape-arc algorithm. Approximated circle, square, or triangle images will be marked as traffic sign and processed in the recognition step with linear c-SVM. SVM classification will be based on binary images which gives 97\% accuracy. The proposed method is more accurate than methods proposed by the reference papers and the detection is able to detect harder problems such as attached signs.},
  timestamp = {2017-06-19T01:17:20Z},
  booktitle = {Proceedings of the 2011 {{International Conference}} on {{Electrical Engineering}} and {{Informatics}}},
  author = {Soendoro, D. and Supriana, I.},
  month = jul,
  year = {2011},
  keywords = {Approximation algorithms,Approximation methods,binary image,CIELab,color-based method,Computer vision,hue,Image color analysis,Image edge detection,linear c-SVM classification,Noise,object detection,object recognition,Ramer-Douglas-Peucker,Ramer-Douglas-Peucker algorithm,Shape,shape arc estimation,shape-arc estimation algorithm,support vector machines,SVM,traffic engineering computing,traffic sign detection,traffic sign recognition},
  pages = {1--6},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\VJ85P548\\Soendoro e Supriana - 2011 - Traffic sign recognition with Color-based Method, .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6MK6PEQU\\6021584.html:text/html}
}

@misc{_unsupervised_????,
  title = {An Unsupervised Approach for Traffic Sign Recognition Based on Bag-of-Visual-Words - {{IEEE Xplore Document}}},
  timestamp = {2017-06-19T02:00:49Z},
  urldate = {2017-06-19},
  url = {http://ieeexplore.ieee.org/document/7863253/},
  file = {An unsupervised approach for traffic sign recognition based on bag-of-visual-words - IEEE Xplore Document:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\C5GXJ9J7\\7863253.html:text/html}
}

@inproceedings{supriyanto_unsupervised_2016,
  title = {An Unsupervised Approach for Traffic Sign Recognition Based on Bag-of-Visual-Words},
  doi = {10.1109/ICITEED.2016.7863253},
  abstract = {There are many ideas to enhance the safety riding. Advanced Driver Assistance System (ADAS) is a system to help the driver more safety. ADAS has a purpose to assist and direct the driver in order to improve traffic safety. Traffic sign recognition is one important part of ADAS. Traffic sign is a warning sign which placed at the side or above the road to provide detail road information to the driver. In this study, we propose an unsupervised approach for traffic sign recognition based on bag-of-visual-word model. Unsupervised approach does not require label data and training process for traffic sign recognition. It helps when we have many data without label. Our experiment was conducted with dataset from German Traffic Sign Recognition Benchmark (GTSRB). It is a public dataset for traffic sign recognition. The results show that, large number of visual word enable the proposed method produce high accuracy and good quality cluster. Although the accuracy in this study is still very low. The reason for that is each image only produces 3-4 number of keypoints. Small size of the images affect the small number of keypoints.},
  timestamp = {2017-06-19T02:07:58Z},
  booktitle = {2016 8th {{International Conference}} on {{Information Technology}} and {{Electrical Engineering}} ({{ICITEE}})},
  author = {Supriyanto, C. and Luthfiarta, A. and Zeniarja, J.},
  month = oct,
  year = {2016},
  keywords = {ADAS,advanced driver assistance system,bag-of-visual-words,BoVW,driver information systems,German Traffic Sign Recognition Benchmark,GTSRB,GTSRB dataset,Hidden Markov models,Histograms,image recognition,road information,Roads,road safety,road traffic,safety riding,SURF,traffic sign recognition,unsupervised approach,unsupervised learning,Vehicles,Visualization,warning sign},
  pages = {1--4},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MAV5JQDS\\Supriyanto et al. - 2016 - An unsupervised approach for traffic sign recognit.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\NHCBTEZS\\7863253.html:text/html}
}

@inproceedings{hammoudi_self-driven_2016,
  title = {Self-Driven and Direct Spatio-Temporal Mechanisms for the Vision-Based Parking Slot Surveillance},
  doi = {10.1109/SAI.2016.7556152},
  abstract = {A vision-based and straightforward parking space surveillance system is presented. In particular, the novelty of the approach lies in the use of self-driven and direct dissimilarity computing mechanisms based on image raw brightness. Notably, the parking occupancy is estimated in real-time by applying fast computed estimators that optimize a global dissimilarity measure over slot-centered parking images. Experimental results show the operational capabilities and the efficiency of the proposed system mechanisms.},
  timestamp = {2017-06-19T02:11:02Z},
  booktitle = {2016 {{SAI Computing Conference}} ({{SAI}})},
  author = {Hammoudi, K. and Benhabiles, H. and Jandial, A. and Dornaika, F. and Mouzna, J.},
  month = jul,
  year = {2016},
  keywords = {Automobiles,Cameras,Car parking surveillance system,Computer vision,direct dissimilarity computing mechanism,direct spatio-temporal mechanism,estimation theory,global dissimilarity measure,image raw brightness,image resolution,Occupancy surveillance mechanisms,parking occupancy,parking space surveillance system,Real-time systems,road traffic,Robustness,self-driven mechanism,Sensors,slot-centered parking image,Smart car parking,Spatio-temporal parking analysis,Surveillance,traffic engineering computing,vision-based parking slot surveillance},
  pages = {1327--1329},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ASZMQJTR\\Hammoudi et al. - 2016 - Self-driven and direct spatio-temporal mechanisms .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\IBKIU6JI\\7556152.html:text/html}
}

@incollection{loce_detection_2017-1,
  title = {Detection of {{Passenger Compartment Violations}}},
  isbn = {978-1-118-97166-6},
  abstract = {A moving violation is any violation of the law committed by the driver of a vehicle while it is in motion. Moving violations can typically be identified by observing the behavior of a vehicle such as its speed or running a stop sign or red traffic light. However, several moving violations require observation into the passenger compartment of a vehicle. Failure to wear seat belts and operating a handheld telecommunications device (i.e., cell phone) while driving are two common passenger compartment violations concerning safety. Another type of passenger compartment violation is related to efficient use of roadways. Managed lanes such as high\textquestiondown\textquestiondown\textquestiondown{}occupancy vehicle (HOV) and high\textquestiondown\textquestiondown\textquestiondown{}occupancy tolling (HOT) lanes require a minimum number of occupants within the vehicle or a tolling price that varies depending upon the number of occupants. Imaging technology and computer vision can provide automated or semiautomated enforcement of these violations. This chapter overviews existing computer vision based methods for seat belt usage, cell phone usage, and HOV/HOT lane enforcements.},
  timestamp = {2017-06-19T02:57:53Z},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7906278},
  booktitle = {Computer {{Vision}} and {{Imaging}} in {{Intelligent Transportation Systems}}},
  publisher = {{Wiley-IEEE Press}},
  author = {Loce, Robert P. and Bala, Raja and Trivedi, Mohan},
  year = {2017},
  pages = {432--},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\XC3M984M\\articleDetails.html:text/html},
  doi = {10.1002/9781118971666.ch4}
}

@misc{thapa_moving_2014,
  title = {Moving {{Object Detection}} and {{Segmentation}} Using {{Frame Differencing}} and {{Summing Technique}} - {{Semantic Scholar}}},
  abstract = {The technology of motion detection has become one of the important research areas in computer vision. In surveillance video this has got a number of applications which range from indoor and outdoor security environment, traffic control, behavior detection during spot activities and for compression of video. In this paper simple but robust moving object detection and segmentation algorithm is proposed. The algorithm is based on the background subtraction. A differencing and summing technique (DST) has been used for the moving object detection and segmentation. This method is simple and low in computational complexity as compared to traditional object identification and segmentation techniques. The experimental results show that the proposed method work efficiently in identifying and segmenting moving objects, both in indoor as well as in outdoor environment with static background.},
  timestamp = {2017-06-19T03:29:16Z},
  urldate = {2017-06-19},
  url = {/paper/Moving-Object-Detection-and-Segmentation-using-Fra-Thapa-Sharma/540de606d9a431e87aa46e88d9a1c77583a9976a},
  author = {Thapa, Gorpal and Sharma, Kalpana},
  year = {2014},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\H9KSZCCZ\\540de606d9a431e87aa46e88d9a1c77583a9976a.html:text/html}
}

@inproceedings{li_detection_2012,
  title = {Detection and Tracking of Moving Object Based on {{PTZ}} Camera},
  doi = {10.1109/ICACI.2012.6463213},
  abstract = {A new background updating algorithm of timely replacement of a central regional background was presented in this paper aiming at the PTZ camera video surveillance scenes. Before the object moving out of the setting field, the camera was static and the background subtraction algorithm was used to detect the moving object. Once the object moving out of the setting field, the camera which was controlled by the program rotates and we used the information of two images before and after the rotation to synthesize a new background for the detection of moving targets. When the target moved out of the setting field of view once again, the same method was employed to control the camera's rotation and updating the background timely. It can detect a moving object accurately and quickly and the timing controlling of the camera's rotation can realize the detection and tracking an object in a dynamic background.},
  timestamp = {2017-06-19T03:46:25Z},
  booktitle = {2012 {{IEEE Fifth International Conference}} on {{Advanced Computational Intelligence}} ({{ICACI}})},
  author = {Li, X. and Chen, Q. and Chen, H.},
  month = oct,
  year = {2012},
  keywords = {background subtraction algorithm,background updating algorithm,camera rotation control,Cameras,central regional background,Filtering algorithms,Heuristic algorithms,image sensors,image sequences,Interference,moving object detection,moving object tracking,object detection,object tracking,pan-tilt-zoom cameras,PTZ camera video surveillance scenes,static subtraction algorithm,Target tracking,video surveillance},
  pages = {493--497},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\XHXQJVWU\\Li et al. - 2012 - Detection and tracking of moving object based on P.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\Z3F3IMQR\\6463213.html:text/html}
}

@inproceedings{li_detection_2012-1,
  title = {Detection and Tracking of Moving Object Based on {{PTZ}} Camera},
  doi = {10.1109/ICACI.2012.6463213},
  abstract = {A new background updating algorithm of timely replacement of a central regional background was presented in this paper aiming at the PTZ camera video surveillance scenes. Before the object moving out of the setting field, the camera was static and the background subtraction algorithm was used to detect the moving object. Once the object moving out of the setting field, the camera which was controlled by the program rotates and we used the information of two images before and after the rotation to synthesize a new background for the detection of moving targets. When the target moved out of the setting field of view once again, the same method was employed to control the camera's rotation and updating the background timely. It can detect a moving object accurately and quickly and the timing controlling of the camera's rotation can realize the detection and tracking an object in a dynamic background.},
  timestamp = {2017-06-19T03:51:19Z},
  booktitle = {2012 {{IEEE Fifth International Conference}} on {{Advanced Computational Intelligence}} ({{ICACI}})},
  author = {Li, X. and Chen, Q. and Chen, H.},
  month = oct,
  year = {2012},
  keywords = {background subtraction algorithm,background updating algorithm,camera rotation control,Cameras,central regional background,Filtering algorithms,Heuristic algorithms,image sensors,image sequences,Interference,moving object detection,moving object tracking,object detection,object tracking,pan-tilt-zoom cameras,PTZ camera video surveillance scenes,static subtraction algorithm,Target tracking,video surveillance},
  pages = {493--497},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\QTJ4V7VI\\Li et al. - 2012 - Detection and tracking of moving object based on P.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\AZBBUH6M\\6463213.html:text/html}
}

@inproceedings{sheikh_background_2009,
  title = {Background {{Subtraction}} for {{Freely Moving Cameras}}},
  doi = {10.1109/ICCV.2009.5459334},
  abstract = {Background subtraction algorithms define the background as parts of a scene that are at rest. Traditionally, these algorithms assume a stationary camera, and identify moving objects by detecting areas in a video that change over time. In this paper, we extend the concept of `subtracting' areas at rest to apply to video captured from a freely moving camera. We do not assume that the background is well-approximated by a plane or that the camera center remains stationary during motion. The method operates entirely using 2D image measurements without requiring an explicit 3D reconstruction of the scene. A sparse model of background is built by robustly estimating a compact trajectory basis from trajectories of salient features across the video, and the background is `subtracted' by removing trajectories that lie within the space spanned by the basis. Foreground and background appearance models are then built, and an optimal pixel-wise foreground/background labeling is obtained by efficiently maximizing a posterior function.},
  timestamp = {2017-06-19T03:51:30Z},
  booktitle = {2009 {{IEEE}} 12th {{International Conference}} on {{Computer Vision}}},
  author = {Sheikh, Y. and Javed, O. and Kanade, T.},
  month = sep,
  year = {2009},
  keywords = {2D image measurement,background appearance model,background subtraction algorithm,Cameras,foreground appearance model,freely moving cameras,optimal pixel-wise background labeling,optimal pixel-wise foreground labeling,posterior function,sparse model,trajectory removal,video signal processing},
  pages = {1219--1225},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\T7SVXQST\\Sheikh et al. - 2009 - Background Subtraction for Freely Moving Cameras.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\8T7S4I3N\\5459334.html:text/html}
}

@article{zamalieva_background_2014,
  title = {Background Subtraction for the Moving Camera: {{A}} Geometric Approach},
  volume = {127},
  issn = {1077-3142},
  shorttitle = {Background Subtraction for the Moving Camera},
  doi = {10.1016/j.cviu.2014.06.007},
  abstract = {Background subtraction is a commonly used technique in computer vision for detecting objects. While there is an extensive literature regarding background subtraction, most of the existing methods assume that the camera is stationary. This assumption limits their applicability to moving camera scenarios. In this paper, we approach the background subtraction problem from a geometric perspective to overcome this limitation. In particular, we introduce a 2.5D background model that describes the scene in terms of both its appearance and geometry. Unlike previous methods, the proposed algorithm does not rely on certain camera motions or assumptions about the scene geometry. The scene is represented as a stack of parallel hypothetical planes each of which is associated with a homography transform. A pixel that belongs to a background scene consistently maps between the consecutive frames based on its transformation with respect to the ``hypothetical plane'' it lies on. This observation disambiguates moving objects from the background. Experiments show that the proposed method, when compared to the recent literature, can successfully detect moving objects in complex scenes and with significant camera motion.},
  timestamp = {2017-06-19T03:53:48Z},
  url = {http://www.sciencedirect.com/science/article/pii/S1077314214001349},
  journal = {Computer Vision and Image Understanding},
  author = {Zamalieva, Daniya and Yilmaz, Alper},
  month = oct,
  year = {2014},
  keywords = {background subtraction,Camera motion,object detection,View geometry},
  pages = {73--85},
  file = {ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\I9INGFDM\\S1077314214001349.html:text/html}
}

@misc{_background_????,
  title = {Background Subtraction Techniques: A Review - {{IEEE Xplore Document}}},
  timestamp = {2017-06-19T04:03:38Z},
  urldate = {2017-06-19},
  url = {http://ieeexplore.ieee.org/document/1400815/},
  file = {Background subtraction techniques\: a review - IEEE Xplore Document:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\VVV8TM5S\\1400815.html:text/html}
}

@inproceedings{piccardi_background_2004,
  title = {Background Subtraction Techniques: A Review},
  volume = {4},
  shorttitle = {Background Subtraction Techniques},
  doi = {10.1109/ICSMC.2004.1400815},
  abstract = {Background subtraction is a widely used approach for detecting moving objects from static cameras. Many different methods have been proposed over the recent years and both the novice and the expert can be confused about their benefits and limitations. In order to overcome this problem, this paper provides a review of the main methods and an original categorisation based on speed, memory requirements and accuracy. Such a review can effectively guide the designer to select the most suitable method for a given application in a principled way. Methods reviewed include parametric and non-parametric background density estimates and spatial correlation approaches.},
  timestamp = {2017-06-19T04:04:09Z},
  booktitle = {2004 {{IEEE International Conference}} on {{Systems}}, {{Man}} and {{Cybernetics}} ({{IEEE Cat}}. {{No}}.{{04CH37583}})},
  author = {Piccardi, M.},
  month = oct,
  year = {2004},
  keywords = {Australia,background density estimation,background subtraction technique,Cameras,Computer vision,Feature extraction,Filters,Geometry,Image motion analysis,Information technology,Layout,object detection,spatial correlation,static cameras,Subtraction techniques,Videos},
  pages = {3099--3104 vol.4},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MUJKR3TM\\1400815.html:text/html}
}

@article{cucchiara_detecting_2003,
  title = {Detecting Moving Objects, Ghosts, and Shadows in Video Streams},
  volume = {25},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2003.1233909},
  abstract = {Background subtraction methods are widely exploited for moving object detection in videos in many applications, such as traffic monitoring, human motion capture, and video surveillance. How to correctly and efficiently model and update the background model and how to deal with shadows are two of the most distinguishing and challenging aspects of such approaches. The article proposes a general-purpose method that combines statistical assumptions with the object-level knowledge of moving objects, apparent objects (ghosts), and shadows acquired in the processing of the previous frames. Pixels belonging to moving objects, ghosts, and shadows are processed differently in order to supply an object-based selective update. The proposed approach exploits color information for both background subtraction and shadow detection to improve object segmentation and background update. The approach proves fast, flexible, and precise in terms of both pixel accuracy and reactivity to background changes.},
  timestamp = {2017-06-19T04:35:11Z},
  number = {10},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Cucchiara, R. and Grana, C. and Piccardi, M. and Prati, A.},
  month = oct,
  year = {2003},
  keywords = {apparent objects,Application software,background modeling,background subtraction methods,background update,color information,color segmentation,ghosts,human motion capture,Image motion analysis,image segmentation,Layout,Monitoring,moving object detection,object-based selective update,object detection,object-level knowledge,object segmentation,pixel processing,shadow detection,Shape,statistical assumptions,Streaming media,Traffic control,traffic monitoring,US Department of Transportation,video streams,video surveillance},
  pages = {1337--1342},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9QNFSRMP\\1233909.html:text/html}
}

@inproceedings{lo_automatic_2001,
  title = {Automatic Congestion Detection System for Underground Platforms},
  doi = {10.1109/ISIMP.2001.925356},
  abstract = {An automatic monitoring system is proposed in this paper for detecting overcrowding conditions in the platforms of underground train services. Whenever overcrowding is detected, the system will notify the station operators to take appropriate actions to prevent accidents, such as people falling off or being pushed onto the tracks. The system is designed to use existing closed circuit television (CCTV) cameras for acquiring images of the platforms. In order to focus on the passengers on the platform, background subtraction and update techniques are used. In addition, due to the high variation of brightness on the platforms, a variance filter is introduced to optimize the removal of background pixels. A multi-layer feed forward neural network was developed for classifying the levels of congestion. The system was tested with recorded video from the London Bridge station, and the testing results were shown to be accurate in identifying overcrowding conditions for the unique platform environment},
  timestamp = {2017-06-19T04:51:25Z},
  booktitle = {Proceedings of 2001 {{International Symposium}} on {{Intelligent Multimedia}}, {{Video}} and {{Speech Processing}}. {{ISIMP}} 2001 ({{IEEE Cat}}. {{No}}.{{01EX489}})},
  author = {Lo, B. P. L. and Velastin, S. A.},
  year = {2001},
  keywords = {Accidents,automatic monitoring,Brightness,Cameras,Circuits,closed circuit television,Computerized monitoring,Condition monitoring,congestion detection system,feedforward neural nets,Feeds,Filters,image processing,Monitoring,multi-layer feed forward neural network,railways,System testing,TV,underground platforms,underground train services,variance filter,variation of brightness},
  pages = {158--161},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6ZMWB9UE\\925356.html:text/html}
}

@inproceedings{lo_automatic_2001-1,
  title = {Automatic Congestion Detection System for Underground Platforms},
  doi = {10.1109/ISIMP.2001.925356},
  abstract = {An automatic monitoring system is proposed in this paper for detecting overcrowding conditions in the platforms of underground train services. Whenever overcrowding is detected, the system will notify the station operators to take appropriate actions to prevent accidents, such as people falling off or being pushed onto the tracks. The system is designed to use existing closed circuit television (CCTV) cameras for acquiring images of the platforms. In order to focus on the passengers on the platform, background subtraction and update techniques are used. In addition, due to the high variation of brightness on the platforms, a variance filter is introduced to optimize the removal of background pixels. A multi-layer feed forward neural network was developed for classifying the levels of congestion. The system was tested with recorded video from the London Bridge station, and the testing results were shown to be accurate in identifying overcrowding conditions for the unique platform environment},
  timestamp = {2017-06-19T04:52:41Z},
  booktitle = {Proceedings of 2001 {{International Symposium}} on {{Intelligent Multimedia}}, {{Video}} and {{Speech Processing}}. {{ISIMP}} 2001 ({{IEEE Cat}}. {{No}}.{{01EX489}})},
  author = {Lo, B. P. L. and Velastin, S. A.},
  year = {2001},
  keywords = {Accidents,automatic monitoring,Brightness,Cameras,Circuits,closed circuit television,Computerized monitoring,Condition monitoring,congestion detection system,feedforward neural nets,Feeds,Filters,image processing,Monitoring,multi-layer feed forward neural network,railways,System testing,TV,underground platforms,underground train services,variance filter,variation of brightness},
  pages = {158--161},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\JMBQXC9J\\925356.html:text/html}
}

@inproceedings{zivkovic_improved_2004,
  title = {Improved Adaptive {{Gaussian}} Mixture Model for Background Subtraction},
  volume = {2},
  doi = {10.1109/ICPR.2004.1333992},
  abstract = {Background subtraction is a common computer vision task. We analyze the usual pixel-level approach. We develop an efficient adaptive algorithm using Gaussian mixture probability density. Recursive equations are used to constantly update the parameters and but also to simultaneously select the appropriate number of components for each pixel.},
  timestamp = {2017-06-19T05:56:20Z},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Pattern Recognition}}, 2004. {{ICPR}} 2004.},
  author = {Zivkovic, Z.},
  month = aug,
  year = {2004},
  keywords = {Adaptive algorithm,adaptive Gaussian mixture model,background subtraction,Cameras,Computer vision,Density functional theory,Equations,Gaussian processes,Intelligent systems,Layout,object detection,Pixel,pixel-level approach,probability density,recursive equations,recursive functions,Surveillance},
  pages = {28--31 Vol.2},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PA4JGQNU\\1333992.html:text/html}
}

@incollection{suetens_model-based_1991,
  title = {Model-{{Based Image Segmentation}}: {{Methods}} and {{Applications}}},
  shorttitle = {Model-{{Based Image Segmentation}}},
  abstract = {We discuss different methods and applications of model-based segmentation of medical images. In this paper model-based segmentation is defined as the assignment of labels to pixels or voxels by matching the a priori known object model to the image data. Labels may have probabilities expressing their uncertainty. Particularly we compare optimization methods with the knowledge-based system approach.},
  language = {en},
  timestamp = {2017-06-19T06:01:05Z},
  urldate = {2017-06-19},
  url = {https://link.springer.com/chapter/10.1007/978-3-642-48650-0_1},
  booktitle = {{{AIME}} 91},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Suetens, P. and Verbeeck, R. and Delaere, D. and Nuyts, J. and Bijnens, B.},
  year = {1991},
  pages = {3--24},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\HJ8QZBS3\\978-3-642-48650-0_1.html:text/html},
  doi = {10.1007/978-3-642-48650-0_1}
}

@inproceedings{fong_edge_2004,
  title = {Edge Model Based Segmentation},
  volume = {3},
  doi = {10.1109/ICPR.2004.1334605},
  abstract = {Segmentation is an important operation in image analysis. It is employed to extract interested objects from an image under test. Much research work has been performed and the optimal graph theoretic approach to data clustering is one of the promising methods. However, when the image size is large, the graph size is very large. As a result the graph becomes complex and its processing is computation demanding. In this paper, we propose to simplify the problem by pre-segmenting the image under test using an edge model before applying the optimal graph theoretic approach to data clustering. The experimental results show that the proposed method can efficiently segments an image with satisfactory results.},
  timestamp = {2017-06-19T06:13:45Z},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Pattern Recognition}}, 2004. {{ICPR}} 2004.},
  author = {Fong, Chi-Keung and Cham, Wai-Keun},
  month = aug,
  year = {2004},
  keywords = {data clustering,Data mining,edge detection,edge model,graph theory,Humans,Image analysis,Image edge detection,image processing,Image representation,image segmentation,Image texture analysis,object extraction,optimal graph theoretic method,optimisation,Partitioning algorithms,pattern clustering,Testing,Video coding},
  pages = {618--621 Vol.3},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\U89M3RB2\\1334605.html:text/html}
}

@misc{_model-based_????,
  title = {Model-Based Segmentation of the Brain from 3-{{D MRI}} Using Active Surfaces - {{IEEE Xplore Document}}},
  timestamp = {2017-06-19T06:16:13Z},
  urldate = {2017-06-19},
  url = {http://ieeexplore.ieee.org/document/404372/},
  file = {Model-based segmentation of the brain from 3-D MRI using active surfaces - IEEE Xplore Document:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9HCHE3H7\\404372.html:text/html}
}

@inproceedings{snell_model-based_1993,
  title = {Model-Based Segmentation of the Brain from 3-{{D MRI}} Using Active Surfaces},
  doi = {10.1109/NEBC.1993.404372},
  abstract = {Traditional segmentation approaches have proven inadequate when faced with the anatomical complexity and variability exhibited by biological structures such as the brain. A 3-D extension to the 'snakes' algorithm has been implemented and used to segment the brain surface from MRI image volumes of the head in an effort to investigate model-based, top-down segmentation strategies. These active surfaces allow closed surfaces of complex objects to be recovered using a priori knowledge in the form of initial conditions and applied external forces. Preliminary results suggest that active surfaces may be initialized according to a preconceived model and adaptively deformed by image data to recover the desired object surface},
  timestamp = {2017-06-19T06:16:18Z},
  booktitle = {1993 {{IEEE Annual Northeast Bioengineering Conference}}},
  author = {Snell, J. W. and Merickel, M. B. and Goble, J. C. and Brookeman, J. B. and Kassell, N. F.},
  month = mar,
  year = {1993},
  keywords = {3-D MRI,Active contours,active surfaces,adaptively deformed,Biomedical engineering,Biomedical imaging,biomedical NMR,Boundary conditions,Brain modeling,brain models,closed surfaces,complex objects,Computer vision,edge detection,energy minimisation,image data,image segmentation,Magnetic resonance imaging,medical image processing,model-based segmentation,Radiology,snakes algorithm,top-down segmentation strategies,Topology},
  pages = {164--165},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9BTZVXUR\\404372.html:text/html}
}

@misc{barrow_interpreting_????,
  title = {Interpreting Line Drawings as Three-Dimensional Surfaces},
  timestamp = {2017-06-20T18:28:16Z},
  urldate = {2017-06-20},
  url = {http://www.sciencedirect.com/science/article/pii/0004370281900217},
  author = {Barrow, H.G. and Tenenbaum, J.M.},
  file = {Interpreting line drawings as three-dimensional surfaces - ScienceDirect:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\XM5ZBBQ6\\0004370281900217.html:text/html}
}

@article{Marr1980TheoryOE,
  title = {Theory of Edge Detection.},
  volume = {207 1167},
  timestamp = {2017-06-20T19:26:08Z},
  journal = {Proceedings of the Royal Society of London. Series B, Biological sciences},
  author = {Marr, D. and Hildreth, E.},
  year = {1980},
  pages = {187--217}
}

@article{canny_computational_1986,
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  volume = {PAMI-8},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.1986.4767851},
  abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
  timestamp = {2017-06-21T10:29:14Z},
  number = {6},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Canny, J.},
  month = nov,
  year = {1986},
  keywords = {Detectors,edge detection,Feature extraction,Gaussian approximation,Image edge detection,image processing,Machine vision,multiscale image analysis,Performance analysis,Shape measurement,Signal synthesis,Signal to noise ratio,Uncertainty},
  pages = {679--698},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\XC83V9GC\\4767851.html:text/html}
}

@misc{labs_theory_2017,
  title = {Theory - {{Virtual Lab}} in {{Image Processing}}},
  timestamp = {2017-06-21T11:17:34Z},
  urldate = {2017-06-21},
  url = {http://cse19-iiith.vlabs.ac.in/theory.php?exp=neigh},
  author = {Labs, Virtual},
  year = {2017},
  file = {Theory - Virtual Lab in Image Processing:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\F4PUVNGD\\theory.html:text/html}
}

@misc{sobel_isotropic_1989,
  title = {An {{Isotropic}} 3 3 {{Image Gradient Operator}} ({{PDF Download Available}})},
  abstract = {Official Full-Text Paper (PDF): An Isotropic 3 3 Image Gradient Operator},
  timestamp = {2017-06-21T12:58:15Z},
  urldate = {2017-06-21},
  url = {https://www.researchgate.net/publication/239398674_An_Isotropic_3_3_Image_Gradient_Operator},
  journal = {ResearchGate},
  author = {Sobel, Irwin},
  year = {1989},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\KWQ32CX6\\239398674_An_Isotropic_3_3_Image_Gradient_Operator.html:text/html}
}

@book{serra_image_1983,
  address = {Orlando, FL, USA},
  title = {Image {{Analysis}} and {{Mathematical Morphology}}},
  isbn = {978-0-12-637240-3},
  timestamp = {2017-06-22T10:40:56Z},
  publisher = {{Academic Press, Inc.}},
  author = {Serra, Jean},
  year = {1983}
}

@book{dougherty_introduction_1992,
  title = {An Introduction to Morphological Image Processing},
  language = {en},
  timestamp = {2017-06-22T10:44:33Z},
  publisher = {{SPIE Optical Engineering Press}},
  author = {Dougherty, Edward R.},
  year = {1992},
  note = {Google-Books-ID: 1kvxAAAAMAAJ},
  keywords = {Computers / Data Processing / Optical Data Processing,Computers / Image Processing,image processing,Image processing/ Digital techniques,Morphisms (Mathematics),Technology \& Engineering / General,Technology \& Engineering / Imaging Systems}
}

@misc{_program_????,
  title = {Program},
  timestamp = {2017-06-22T10:47:51Z},
  urldate = {2017-06-22},
  url = {https://www.pearson.com/us/higher-education/program/Gonzalez-Digital-Image-Processing-4th-Edition/PGM241219.html},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\DVEQJUSC\\PGM241219.html:text/html}
}

@book{gonzalez_digital_1992,
  title = {Digital {{Image Processing}}},
  timestamp = {2017-06-22T10:49:48Z},
  author = {Gonzalez, Rafael C. and Woods, Richard E.},
  year = {1992}
}

@book{jain_fundamentals_1989,
  title = {Fundamentals of {{Digital Image Processing}}},
  isbn = {978-0-13-336165-0},
  abstract = {Presents a thorough overview of the major topics of digital image processing, beginning with the basic mathematical tools needed for the subject. Includes a comprehensive chapter on stochastic models for digital image processing.Covers aspects of image representation including luminance, color, spatial and temporal properties of vision, and digitization. Explores various image processing techniques. Discusses algorithm development (software/firmware) for image transforms, enhancement, reconstruction, and image coding.},
  language = {en},
  timestamp = {2017-06-22T13:47:00Z},
  publisher = {{Prentice Hall}},
  author = {Jain, Anil K.},
  year = {1989},
  note = {Google-Books-ID: GANSAAAAMAAJ},
  keywords = {Technology \& Engineering / Electrical,Technology \& Engineering / Imaging Systems,Technology \& Engineering / Telecommunications}
}

@misc{fisher_morphology_2003,
  title = {Morphology},
  timestamp = {2017-06-22T15:13:57Z},
  urldate = {2017-06-22},
  url = {http://homepages.inf.ed.ac.uk/rbf/HIPR2/morops.htm},
  author = {Fisher, R. and Perkins, S. and Walker, A. and Wolfart},
  year = {2003},
  file = {Morphology:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\WFW3JCDB\\morops.html:text/html}
}

@inproceedings{qianyin_model_2015,
  title = {A Model Based Method of Pedestrian Abnormal Behavior Detection in Traffic Scene},
  doi = {10.1109/ISC2.2015.7366164},
  abstract = {In order to reduce traffic accidents caused by the pedestrian, five kinds of dangerous pedestrian abnormal behaviors are studied in the paper. A behavior model between the pedestrian trajectory and the road is built to describe the five kinds of dangerous pedestrian abnormal behaviors: crossing road border, illegal stay, crossing the road, moving along the curb, entering road area. The method contains pedestrian detection, shadow elimination, pedestrian recognition, pedestrian tracking and abnormal behavior detection. Background subtraction method is used to detect moving targets. After shadow elimination, pedestrians are distinguished from vehicles according to the ratio. Then, pedestrian trajectories are gotten by pedestrian tracking. Finally, based on the relation between trajectory and road, the model of five kinds of pedestrian abnormal behaviors is established, and abnormal behaviors are detected according this model. Experiments show that the method can distinguish and detect the pedestrian abnormal behaviors effectively in short time, and it is suitable to use in real time traffic monitoring.},
  timestamp = {2017-06-22T18:21:22Z},
  booktitle = {2015 {{IEEE First International Smart Cities Conference}} ({{ISC2}})},
  author = {Qianyin, J. and Guoming, L. and Jinwei, Y. and Xiying, L.},
  month = oct,
  year = {2015},
  keywords = {Background subtraction method,computerised monitoring,model based method,moving target detection,object detection,object recognition,pedestrian abnormal behavior detection,pedestrian abnormal behavior model,pedestrian detection,pedestrian recognition,pedestrians,pedestrian tracking,pedestrian trajectory,real time traffic monitoring,road accidents,road vehicles,shadow elimination,Target tracking,traffic accident reduction,traffic engineering computing,traffic surveillance video,video surveillance},
  pages = {1--6},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6F2X3V8I\\icp.html:text/html}
}

@inproceedings{miao_size_2011,
  title = {Size and Angle Filter Based Rain Removal in Video for Outdoor Surveillance Systems},
  abstract = {Rain presents a challenge for outdoor surveillance systems, because raindrops can cause temporal and random noise, which in turn affects the performance of vision systems. This paper presents a method to remove the effects of raindrops using two continuous frames in a video. The two adjacent frames are assumed to have the same background and the raindrops do not overlap in the two images. Thus, the rain-affected pixels can be identified by finding the changes in RGB values between the two adjacent frames. Finally, the false candidate rain-affected pixels are filtered using the properties of raindrops in images such as speed and size. The performance of the proposed algorithm on rainy videos shows that the algorithm can effectively remove the raindrops in real time for outdoor videos.},
  timestamp = {2017-06-22T19:12:14Z},
  booktitle = {2011 8th {{Asian Control Conference}} ({{ASCC}})},
  author = {Miao, Y. and Hong, H. and Kim, H.},
  month = may,
  year = {2011},
  keywords = {angle filter,Cameras,de-raining,de-weathering,Filtering,image colour analysis,outdoor surveillance,outdoor surveillance systems,Pixel,rain,rain-affected pixels,raindrop removal,Rain removal,RGB value,Streaming media,Surveillance,video surveillance},
  pages = {1300--1304},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\JPEEAAZF\\Miao et al. - 2011 - Size and angle filter based rain removal in video .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\EQWPJNRU\\5899260.html:text/html}
}

@inproceedings{shiting_clustering-based_2013,
  title = {Clustering-Based Shadow Edge Detection in a Single Color Image},
  doi = {10.1109/MEC.2013.6885215},
  abstract = {Shadow edge detection is an important and challenging part of shadow detection and removal. In this paper, we propose a clustering-based shadow edge detection method, which can avoid choosing parameters by the hysteresis step in the Canny edge detection process in Finlayson's method. First, K-means clustering is applied to the derivative difference of the brightness image and light-invariant image from raw input. Second, punishment rules are exploited to correct false alarms. Plus, putting off morphological dilation prevents from introducing extra material edges into shadow edge mask. Experimental results show that compared with Finlayson's work, our method can effectively generate complete enough shadow edge mask. Importantly, parameters of our method are not affected by Canny detection and Mean-shift smoothing processing, thus producing robust and stable results in both indoor and outdoor scenes.},
  timestamp = {2017-06-22T21:36:19Z},
  booktitle = {Proceedings 2013 {{International Conference}} on {{Mechatronic Sciences}}, {{Electric Engineering}} and {{Computer}} ({{MEC}})},
  author = {Shiting, Wang and Hong, Zheng},
  month = dec,
  year = {2013},
  keywords = {Brightness,brightness image,Canny edge detection proces,clustering,Clustering algorithms,clustering-based shadow edge detection,edge detection,Educational institutions,Finlayson method,hysteresis step,illumination invariance,image colour analysis,Image edge detection,K-means clustering,Lighting,light-invariant image,Materials,morphological dilation,Noise,pattern clustering,punishment rules,shadow detection,shadow edge mask,shadow removal,single color image},
  pages = {1038--1041},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\BUT78D73\\Shiting e Hong - 2013 - Clustering-based shadow edge detection in a single.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\W4NE8A7G\\6885215.html:text/html}
}

@inproceedings{prati_shadow_2001,
  title = {Shadow Detection Algorithms for Traffic Flow Analysis: A Comparative Study},
  shorttitle = {Shadow Detection Algorithms for Traffic Flow Analysis},
  doi = {10.1109/ITSC.2001.948680},
  abstract = {Shadow detection is critical for robust and reliable vision-based systems for traffic flow analysis. In this paper we discuss various shadow detection approaches and compare two critically. The goal of these algorithms is to prevent moving shadows being misclassified as moving objects (or parts of them), thus avoiding the merging of two or more objects into one and improving the accuracy of object localization. The environment considered is an outdoor highway scene with multiple lanes observed by a single fixed camera. The important features of shadow detection algorithms and the parameter set-up are analyzed and discussed. A critical evaluation of the results both in terms of accuracy and in terms of computational complexity are outlined. Finally, possible integration of the two approaches into a robust shadow detector is presented as future direction of our research},
  timestamp = {2017-06-22T21:59:05Z},
  booktitle = {{{ITSC}} 2001. 2001 {{IEEE Intelligent Transportation Systems}}. {{Proceedings}} ({{Cat}}. {{No}}.{{01TH8585}})},
  author = {Prati, A. and Mikic, I. and Grana, C. and Trivedi, M. M.},
  year = {2001},
  keywords = {Algorithm design and analysis,Cameras,computational complexity,Computer vision,Detection algorithms,Detectors,image recognition,Layout,Merging,moving shadows,road traffic,Road transportation,Robustness,shadow detection,traffic engineering computing,traffic flow analysis,vision-based systems},
  pages = {340--345},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\HKWS6JGH\\948680.html:text/html}
}

@inproceedings{mikic_moving_2000,
  title = {Moving Shadow and Object Detection in Traffic Scenes},
  volume = {1},
  doi = {10.1109/ICPR.2000.905341},
  abstract = {We present an algorithm for segmentation of traffic scenes that distinguishes moving objects from their moving cast shadows. A fading memory estimator calculates mean and variance of all three color components for each background pixel. Given the statistics for a background pixel, simple rules for calculating its statistics when covered by a shadow are used. Then, MAP classification decisions are made for each pixel. In addition to the color features, we examine the use of neighborhood information to produce smoother classification. We also propose the use of temporal information by modifying class a priori probabilities based on predictions from the previous frame},
  timestamp = {2017-06-22T22:42:16Z},
  booktitle = {Proceedings 15th {{International Conference}} on {{Pattern Recognition}}. {{ICPR}}-2000},
  author = {Mikic, I. and Cosman, P. C. and Kogut, G. T. and Trivedi, M. M.},
  year = {2000},
  keywords = {class a priori probabilities,Data mining,Fading,fading memory estimator,image segmentation,Information resources,Layout,moving shadow detection,neighborhood information,object detection,Probability,road traffic,Robustness,statistical analysis,Statistics,temporal information,Traffic control,traffic scene segmentation},
  pages = {321--324 vol.1},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6228WNBX\\905341.html:text/html}
}

@inproceedings{cucchiara_statistic_2000,
  title = {Statistic and Knowledge-Based Moving Object Detection in Traffic Scenes},
  doi = {10.1109/ITSC.2000.881013},
  abstract = {The most common approach used for vision-based traffic surveillance consists of a fast segmentation of moving visual objects (MVOs) in the scene together with an intelligent reasoning module capable of identifying, tracking and classifying the MVOs in dependency of the system goal. In this paper we describe our approach for MVOs segmentation in an unstructured traffic environment. We consider complex situations with moving people, vehicles and infrastructures that have different aspect model and motion model. In this case we define a specific approach based on background subtraction with statistic and knowledge-based background update. We show many results of real-time tracking of traffic MVOs in outdoor traffic scene such as roads, parking area intersections, and entrance with barriers},
  timestamp = {2017-06-22T23:40:47Z},
  booktitle = {{{ITSC2000}}. 2000 {{IEEE Intelligent Transportation Systems}}. {{Proceedings}} ({{Cat}}. {{No}}.{{00TH8493}})},
  author = {Cucchiara, R. and Grana, C. and Piccardi, M. and Prati, A.},
  year = {2000},
  keywords = {background subtraction,Computer vision,Data mining,image segmentation,image sequences,Intelligent transportation systems,knowledge based systems,knowledge-based systems,Layout,Machine vision,Monitoring,moving object detection,object detection,optical flow,optical tracking,Real-time systems,road traffic,statistical analysis,Statistics,Surveillance,Tracking,Traffic control,traffic engineering computing,traffic surveillance,Vehicle dynamics},
  pages = {27--32},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\N6FP53AE\\881013.html:text/html}
}

@article{coifman_real-time_1998,
  title = {A Real-Time Computer Vision System for Vehicle Tracking and Traffic Surveillance},
  volume = {6},
  issn = {0968-090X},
  doi = {10.1016/S0968-090X(98)00019-9},
  abstract = {Increasing congestion on freeways and problems associated with existing detectors have spawned an interest in new vehicle detection technologies such as video image processing. Existing commercial image processing systems work well in free-flowing traffic, but the systems have difficulties with congestion, shadows and lighting transitions. These problems stem from vehicles partially occluding one another and the fact that vehicles appear differently under various lighting conditions. We are developing a feature-based tracking system for detecting vehicles under these challenging conditions. Instead of tracking entire vehicles, vehicle features are tracked to make the system robust to partial occlusion. The system is fully functional under changing lighting conditions because the most salient features at the given moment are tracked. After the features exit the tracking region, they are grouped into discrete vehicles using a common motion constraint. The groups represent individual vehicle trajectories which can be used to measure traditional traffic parameters as well as new metrics suitable for improved automated surveillance. This paper describes the issues associated with feature based tracking, presents the real-time implementation of a prototype system, and the performance of the system on a large data set. \textcopyright{}},
  timestamp = {2017-06-23T00:48:59Z},
  number = {4},
  url = {http://www.sciencedirect.com/science/article/pii/S0968090X98000199},
  journal = {Transportation Research Part C: Emerging Technologies},
  author = {Coifman, Benjamin and Beymer, David and McLauchlan, Philip and Malik, Jitendra},
  month = aug,
  year = {1998},
  keywords = {Machine vision,traffic surveillance,vehicle tracking,Video image processing,Wide-area detection},
  pages = {271--288},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\VTNT98RR\\Coifman et al. - 1998 - A real-time computer vision system for vehicle tra.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\2ZR76C5R\\S0968090X98000199.html:text/html}
}

@article{samet_efficient_1988,
  title = {Efficient Component Labeling of Images of Arbitrary Dimension Represented by Linear Bintrees},
  volume = {10},
  issn = {0162-8828},
  doi = {10.1109/34.3918},
  abstract = {An algorithm is presented to perform connected-component labeling of images of arbitrary dimension that are represented by a linear bintree. The bintree is a generalization of the quadtree data structure that enables dealing with images of arbitrary dimension. The linear bintree is a pointerless representation. The algorithm uses an active border which is represented by linked lists instead of arrays. This results in a significant reduction in the space requirements, thereby making it feasible to process three- and higher-dimensional images. Analysis of the execution time of the algorithm shows almost linear behavior with respect to the number of leaf nodes in the image, and empirical tests are in agreement. The algorithm can be modified easily to compute a (d-1)-dimensional boundary measure (e.g. perimeter in two dimensions and surface area in three dimensions) with linear performance},
  timestamp = {2017-06-23T01:15:00Z},
  number = {4},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Samet, H. and Tamminen, M.},
  month = jul,
  year = {1988},
  keywords = {Algorithm design and analysis,Area measurement,component labeling,Computer graphics,computerised pattern recognition,computerised picture processing,data structures,Design automation,Image analysis,image processing,Labeling,linear bintrees,Pixel,pointerless representation,quadtree data structure,Testing,trees (mathematics)},
  pages = {579--586},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\KGBP46HN\\3918.html:text/html}
}

@inproceedings{abubaker_one_2007,
  title = {One {{Scan Connected Component Labeling Technique}}},
  doi = {10.1109/ICSPC.2007.4728561},
  abstract = {This paper, presents a new component labeling algorithm which is based on scanning and labeling the objects in a single scan. The algorithm has the ability to test the four and eight connected branches of the object. This algorithm, which is fast and requires low memory allocation, can also process an image that contains large numbers of objects. The algorithm is used to scan the image from left to right and from top to bottom to find the unlabeled objects. A comparison analysis is performed with other component labeling algorithms. Our algorithm has shown an outstanding performance with respect to the processing time. A practical application with computer based mammography is also included.},
  timestamp = {2017-06-23T14:44:37Z},
  booktitle = {2007 {{IEEE International Conference}} on {{Signal Processing}} and {{Communications}}},
  author = {AbuBaker, A. and Qahwaji, R. and Ipson, S. and Saleh, M.},
  month = nov,
  year = {2007},
  keywords = {Application software,comparison analysis,component labeling technique,computer based mammography,Connected Component Labeling,Image analysis,Image coding,image processing,Image storage,Informatics,Labeling,Mammograms,mammography,Performance analysis,Pixel,Signal processing,Signal processing algorithms,Testing},
  pages = {1283--1286},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\GMG9KT6M\\AbuBaker et al. - 2007 - One Scan Connected Component Labeling Technique.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\66ZXJQNH\\4728561.html:text/html}
}

@inproceedings{grana_yacclab_2016,
  title = {{{YACCLAB}} - {{Yet Another Connected Components Labeling Benchmark}}},
  doi = {10.1109/ICPR.2016.7900112},
  abstract = {The problem of labeling the connected components (CCL) of a binary image is well-defined and several proposals have been presented in the past. Since an exact solution to the problem exists and should be mandatory provided as output, algorithms mainly differ on their execution speed. In this paper, we propose and describe YACCLAB, Yet Another Connected Components Labeling Benchmark. Together with a rich and varied dataset, YACCLAB contains an open source platform to test new proposals and to compare them with publicly available competitors. Textual and graphical outputs are automatically generated for three kinds of test, which analyze the methods from different perspectives. The fairness of the comparisons is guaranteed by running on the same system and over the same datasets. Examples of usage and the corresponding comparisons among state-of-the-art techniques are reported to confirm the potentiality of the benchmark.},
  timestamp = {2017-06-23T15:21:40Z},
  booktitle = {2016 23rd {{International Conference}} on {{Pattern Recognition}} ({{ICPR}})},
  author = {Grana, C. and Bolelli, F. and Baraldi, L. and Vezzani, R.},
  month = dec,
  year = {2016},
  keywords = {Algorithm design and analysis,Benchmark testing,binary image,Computer vision,connected components labeling benchmark,Decision trees,image resolution,Labeling,Licenses,object recognition,Proposals,YACCLAB},
  pages = {3109--3114},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\DMFJS8M8\\Grana et al. - 2016 - YACCLAB - Yet Another Connected Components Labelin.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\IDP3TAK2\\7900112.html:text/html}
}

@misc{wikipedia_connected_2017,
  title = {Connected Component Labeling},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {Connected-component labeling (alternatively connected-component analysis, blob extraction, region labeling, blob discovery, or region extraction) is an algorithmic application of graph theory, where subsets of connected components are uniquely labeled based on a given heuristic. Connected-component labeling is not to be confused with segmentation.
Connected-component labeling is used in computer vision to detect connected regions in binary digital images, although color images and data with higher dimensionality can also be processed. When integrated into an image recognition system or human-computer interaction interface, connected component labeling can operate on a variety of information. Blob extraction is generally performed on the resulting binary image from a thresholding step. Blobs may be counted, filtered, and tracked.
Blob extraction is related to but distinct from blob detection.},
  language = {en},
  timestamp = {2017-06-23T16:06:32Z},
  url = {https://en.wikipedia.org/w/index.php?title=Connected-component_labeling\&oldid=783324000},
  journal = {Wikipedia},
  author = {Wikipedia},
  month = jun,
  year = {2017},
  note = {Page Version ID: 783324000},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\EF6IMS3A\\index.html:text/html}
}

@article{chang_linear-time_2004,
  title = {A Linear-Time Component-Labeling Algorithm Using Contour Tracing Technique},
  volume = {93},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2003.09.002},
  abstract = {A new linear-time algorithm is presented in this paper that simultaneously labels connected components (to be referred to merely as components in this paper) and their contours in binary images. The main step of this algorithm is to use a contour tracing technique to detect the external contour and possible internal contours of each component, and also to identify and label the interior area of each component. Labeling is done in a single pass over the image, while contour points are revisited more than once, but no more than a constant number of times. Moreover, no re-labeling is required throughout the entire process, as it is required by other algorithms. Experimentation on various types of images (characters, half-tone pictures, photographs, newspaper, etc.) shows that our method outperforms methods that use the equivalence technique. Our algorithm not only labels components but also extracts component contours and sequential orders of contour points, which can be useful for many applications.},
  timestamp = {2017-06-23T18:34:45Z},
  number = {2},
  url = {http://www.sciencedirect.com/science/article/pii/S1077314203001401},
  journal = {Computer Vision and Image Understanding},
  author = {Chang, Fu and Chen, Chun-Jen and Lu, Chi-Jen},
  month = feb,
  year = {2004},
  keywords = {Component-labeling algorithm,Contour tracing,Linear-time algorithm},
  pages = {206--220},
  file = {ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7AWXC66C\\S1077314203001401.html:text/html}
}

@article{chang_linear-time_2004-1,
  title = {A Linear-Time Component-Labeling Algorithm Using Contour Tracing Technique},
  volume = {93},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2003.09.002},
  abstract = {A new linear-time algorithm is presented in this paper that simultaneously labels connected components (to be referred to merely as components in this paper) and their contours in binary images. The main step of this algorithm is to use a contour tracing technique to detect the external contour and possible internal contours of each component, and also to identify and label the interior area of each component. Labeling is done in a single pass over the image, while contour points are revisited more than once, but no more than a constant number of times. Moreover, no re-labeling is required throughout the entire process, as it is required by other algorithms. Experimentation on various types of images (characters, half-tone pictures, photographs, newspaper, etc.) shows that our method outperforms methods that use the equivalence technique. Our algorithm not only labels components but also extracts component contours and sequential orders of contour points, which can be useful for many applications.},
  timestamp = {2017-06-24T07:25:03Z},
  number = {2},
  url = {http://www.sciencedirect.com/science/article/pii/S1077314203001401},
  journal = {Computer Vision and Image Understanding},
  author = {Chang, Fu and Chen, Chun-Jen and Lu, Chi-Jen},
  month = feb,
  year = {2004},
  keywords = {Component-labeling algorithm,Contour tracing,Linear-time algorithm},
  pages = {206--220},
  file = {ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\VQ5TFGA3\\S1077314203001401.html:text/html}
}

@article{martin-herrero_hybrid_2007,
  title = {Hybrid Object Labelling in Digital Images},
  volume = {18},
  doi = {10.1007/s00138-006-0041-3},
  abstract = {The application of a technique for labelling connected components based on the classical recursive technique is studied. The recursive approach permits labelling, counting, and characterizing objects with a single pass. Its main drawback lies on its very nature: Big objects require a high number of recursive calls, which require a large stack to store local variables and register values. Thus, the risk of stack overflow imposes an impractical limit on image size. The hybrid alternative combines recursion with iterative scanning and can be directly substituted into any program already using the recursive technique. I show how this alternative drastically reduces the number of consecutive recursive calls, and thus the required stack size, while improving overall performance. The method is tested on sets of uniform random binary images and binary images with a random distribution of overlapping square blocks. These test sets provide insight on the adequacy of the algorithm for different applications. The performance of the proposed technique is compared with the classical recursive technique and with an iterative two-pass algorithm using the Union-Find data structure, and the results show an overall increase of speed. The performance of the algorithm in real world machine vision applications is also shown. \textcopyright{} Springer-Verlag 2007.},
  timestamp = {2017-06-24T07:35:21Z},
  number = {1},
  journal = {Machine Vision and Applications},
  author = {Mart{\'\i}n-Herrero, J.},
  year = {2007},
  keywords = {Connected components,Object labelling,Recursive labelling},
  pages = {1--15},
  annote = {Cited By :21},
  file = {SCOPUS Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\G3SPZ4ZD\\display.html:text/html}
}

@misc{_scopus_????,
  title = {Scopus - {{Document}} Details},
  timestamp = {2017-06-24T09:28:41Z},
  urldate = {2017-06-24},
  url = {https://www.scopus.com/record/display.uri?eid=2-s2.0-77954601627\&origin=inward\&txGid=BE02FD67A12419FBDD5DD8957B93A9DD.wsnAw8kcdt7IPYLO0V48gA\%3a42},
  file = {Scopus - Document details:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\K5AMI754\\display.html:text/html}
}

@article{he_run-based_2010,
  title = {A {{Run}}-Based One-and-a-Half-Scan Connected-Component Labeling Algorithm},
  volume = {24},
  doi = {10.1142/S0218001410008032},
  abstract = {This paper presents a run- and label-equivalence-based one-and-a-half-scan algorithm for labeling connected components in a binary image. Major differences between our algorithm and conventional label-equivalence-based algorithms are: (1) all conventional label-equivalence-based algorithms scan all pixels in the given image at least twice, whereas our algorithm scans background pixels once and object pixels twice; (2) all conventional label-equivalence-based algorithms assign a provisional label to each object pixel in the first scan and relabel the pixel in the later scan(s), whereas our algorithm assigns a provisional label to each run in the first scan, and after resolving label equivalences between runs, by using the recorded run data, it assigns each object pixel a final label directly. That is, in our algorithm, relabeling of object pixels is not necessary any more. Experimental results demonstrated that our algorithm is highly efficient on images with many long runs and/or a small number of object pixels. Moreover, our algorithm is directly applicable to run-length-encoded images, and we can obtain contours of connected components efficiently. \textcopyright{} 2010 World Scientific Publishing Company.},
  timestamp = {2017-06-24T09:29:55Z},
  number = {4},
  journal = {International Journal of Pattern Recognition and Artificial Intelligence},
  author = {He, L. and Chao, Y. and Suzuki, K.},
  year = {2010},
  keywords = {connected component,label equivalence,Labeling algorithm,raster scan,run-length encoding},
  pages = {557--579},
  annote = {Cited By :18},
  file = {SCOPUS Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\UZP6GGKW\\display.html:text/html}
}

@book{berg_computational_2008,
  title = {Computational {{Geometry}}: {{Algorithms}} and {{Applications}}},
  isbn = {978-3-540-77973-5},
  shorttitle = {Computational {{Geometry}}},
  abstract = {Computational geometry emerged from the ?eld of algorithms design and analysis in the late 1970s. It has grown into a recognized discipline with its own journals, conferences, and a large community of active researchers. The success of the ?eld as a research discipline can on the one hand be explained from the beauty of the problems studied and the solutions obtained, and, on the other hand, by the many application domains\textemdash{}computer graphics, geographic information systems (GIS), robotics, and others\textemdash{}in which geometric algorithms play a fundamental role. For many geometric problems the early algorithmic solutions were either slow or dif?cult to understand and implement. In recent years a number of new algorithmic techniques have been developed that improved and simpli?ed many of the previous approaches. In this textbook we have tried to make these modern algorithmic solutions accessible to a large audience. The book has been written as a textbook for a course in computational geometry, but it can also be used for self-study.},
  language = {en},
  timestamp = {2017-06-24T17:23:42Z},
  publisher = {{Springer Science \& Business Media}},
  author = {de Berg, Mark},
  month = mar,
  year = {2008},
  note = {Google-Books-ID: tkyG8W2163YC},
  keywords = {Computers / Computer Graphics,Computers / Computer Science,Computers / Databases / General,Computers / Data Processing,Computers / Information Technology,Computers / Programming / Algorithms,Mathematics / Discrete Mathematics,Mathematics / Geometry / General,Science / Earth Sciences / General,Technology \& Engineering / General}
}

@article{chazelle_optimal_1993,
  title = {An Optimal Convex Hull Algorithm in Any Fixed Dimension},
  volume = {10},
  issn = {0179-5376, 1432-0444},
  doi = {10.1007/BF02573985},
  abstract = {We present a deterministic algorithm for computing the convex hull ofn points inEd in optimalO(n logn+n$\llcorner$d/2$\lrcorner$) time. Optimal solutions were previously known only in even dimension and in dimension 3. A by-product of our result is an algorithm for computing the Voronoi diagram ofn points ind-space in optimalO(n logn+n$\ulcorner$d/2$\urcorner$) time.},
  language = {en},
  timestamp = {2017-06-24T19:40:42Z},
  number = {4},
  urldate = {2017-06-24},
  url = {https://link.springer.com/article/10.1007/BF02573985},
  journal = {Discrete \& Computational Geometry},
  author = {Chazelle, Bernard},
  month = dec,
  year = {1993},
  pages = {377--409},
  file = {Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PPIBMGEZ\\Chazelle - 1993 - An optimal convex hull algorithm in any fixed dime.pdf:application/pdf;Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\D6ISV3NK\\BF02573985.html:text/html}
}

@article{grana_optimized_2010,
  title = {Optimized {{Block}}-{{Based Connected Components Labeling With Decision Trees}}},
  volume = {19},
  issn = {1057-7149},
  doi = {10.1109/TIP.2010.2044963},
  abstract = {In this paper, we define a new paradigm for eight-connection labeling, which employes a general approach to improve neighborhood exploration and minimizes the number of memory accesses. First, we exploit and extend the decision table formalism introducing or-decision tables, in which multiple alternative actions are managed. An automatic procedure to synthesize the optimal decision tree from the decision table is used, providing the most effective conditions evaluation order. Second, we propose a new scanning technique that moves on a 2 ?? 2 pixel grid over the image, which is optimized by the automatically generated decision tree. An extensive comparison with the state of art approaches is proposed, both on synthetic and real datasets. The synthetic dataset is composed of different sizes and densities random images, while the real datasets are an artistic image analysis dataset, a document analysis dataset for text detection and recognition, and finally a standard resolution dataset for picture segmentation tasks. The algorithm provides an impressive speedup over the state of the art algorithms.},
  timestamp = {2017-06-25T12:44:47Z},
  number = {6},
  journal = {IEEE Transactions on Image Processing},
  author = {Grana, C. and Borghesani, D. and Cucchiara, R.},
  month = jun,
  year = {2010},
  keywords = {Algorithms,artistic image analysis dataset,Connected components labeling,Decision Support Techniques,decision table formalism,decision tables,Decision trees,document analysis dataset,document image processing,Image Enhancement,Image Interpretation; Computer-Assisted,image recognition,image resolution,image segmentation,optimization methods,optimized block-based connected component labeling,Pattern Recognition; Automated,picture segmentation tasks,Product Labeling,random image density,Reproducibility of Results,scanning technique,Sensitivity and Specificity,synthetic dataset,text analysis,text detection,text recognition},
  pages = {1596--1609},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\C9I9C778\\Grana et al. - 2010 - Optimized Block-Based Connected Components Labelin.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6T5MDP2A\\5428863.html:text/html}
}

@inproceedings{beymer_real-time_1997,
  title = {A Real-Time Computer Vision System for Measuring Traffic Parameters},
  doi = {10.1109/CVPR.1997.609371},
  abstract = {For the problem of tracking vehicles on freeways using machine vision, existing systems work well in free-flowing traffic. Traffic engineers, however, are more interested in monitoring freeways when there is congestion, and current systems break down for congested traffic due to the problem of partial occlusion. We are developing a feature-based tracking approach for the task of tracking vehicles under congestion. Instead of tracking entire vehicles, vehicle sub-features are tracked to make the system robust to partial occlusion. In order to group together sub-features that come from the same vehicle, the constraint of common motion is used. In this paper we describe the system, a real-time implementation using a network of DSP chips, and experiments of the system on approximately 44 lane hours of video data},
  timestamp = {2017-06-25T19:08:47Z},
  booktitle = {Proceedings of {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Beymer, D. and McLauchlan, P. and Coifman, B. and Malik, J.},
  month = jun,
  year = {1997},
  keywords = {Automotive engineering,Computer vision,Detectors,digital signal processing chips,DSP chips,feature-based tracking approach,free-flowing traffic,freeways,Land vehicles,Layout,Machine vision,partial occlusion,real-time computer vision system,Real-time systems,Real time systems,road traffic,road vehicles,Telecommunication traffic,Traffic control,traffic engineering computing,traffic parameters measurements,vehicles tracking},
  pages = {495--501},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\87JK5GEB\\609371.html:text/html}
}

@inproceedings{beymer_real-time_1997-1,
  title = {A Real-Time Computer Vision System for Measuring Traffic Parameters},
  doi = {10.1109/CVPR.1997.609371},
  abstract = {For the problem of tracking vehicles on freeways using machine vision, existing systems work well in free-flowing traffic. Traffic engineers, however, are more interested in monitoring freeways when there is congestion, and current systems break down for congested traffic due to the problem of partial occlusion. We are developing a feature-based tracking approach for the task of tracking vehicles under congestion. Instead of tracking entire vehicles, vehicle sub-features are tracked to make the system robust to partial occlusion. In order to group together sub-features that come from the same vehicle, the constraint of common motion is used. In this paper we describe the system, a real-time implementation using a network of DSP chips, and experiments of the system on approximately 44 lane hours of video data},
  timestamp = {2017-06-25T19:12:09Z},
  booktitle = {Proceedings of {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Beymer, D. and McLauchlan, P. and Coifman, B. and Malik, J.},
  month = jun,
  year = {1997},
  keywords = {Automotive engineering,Computer vision,Detectors,digital signal processing chips,DSP chips,feature-based tracking approach,free-flowing traffic,freeways,Land vehicles,Layout,Machine vision,partial occlusion,real-time computer vision system,Real-time systems,Real time systems,road traffic,road vehicles,Telecommunication traffic,Traffic control,traffic engineering computing,traffic parameters measurements,vehicles tracking},
  pages = {495--501},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\5ZM8GD5S\\609371.html:text/html}
}

@misc{_traffic_????,
  title = {Traffic Management Industry Value to Grow 160\% in Five Years | {{Smart Highways Magazine}}: {{Industry News}}},
  timestamp = {2017-06-26T03:14:38Z},
  urldate = {2017-06-26},
  url = {http://smarthighways.net/traffic-management-industry-value-to-grow-160-in-five-years/},
  author = {null, Smart Highways Magazine},
  file = {Traffic management industry value to grow 160% in five years | Smart Highways Magazine\: Industry News:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\UTDH7XCB\\traffic-management-industry-value-to-grow-160-in-five-years.html:text/html}
}

@misc{_traffic_????-1,
  title = {Traffic {{Management Market}} Worth 59.48 {{Billion USD}} by 2022},
  timestamp = {2017-06-26T03:26:29Z},
  urldate = {2017-06-26},
  url = {http://www.marketsandmarkets.com/PressReleases/traffic-management.asp},
  file = {Traffic Management Market worth 59.48 Billion USD by 2022:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\FS3Z5VZS\\traffic-management.html:text/html}
}

@misc{reportlinker_global_2017,
  title = {Global {{Video Analytics Market}} 2017-2021 - Market Research Report},
  timestamp = {2017-06-26T03:31:53Z},
  urldate = {2017-06-26},
  url = {http://www.reportlinker.com/p04796635/Global-Video-Analytics-Market.html},
  author = {ReportLinker},
  year = {2017},
  file = {Global Video Analytics Market 2017-2021 - market research report:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\TC7CMMER\\Global-Video-Analytics-Market.html:text/html}
}

@misc{navigant_transportation_2017,
  title = {Transportation {{Forecast}}: {{Light Duty Vehicles}}},
  shorttitle = {Transportation {{Forecast}}},
  abstract = {The emerging potential of automated driving technologies promises to disrupt the global transportation system. Theoretically, automation allows users to dramatically improve cost, time, and space e\ldots{}},
  timestamp = {2017-06-26T09:10:55Z},
  urldate = {2017-06-26},
  url = {http://www.navigantresearch.com/research/transportation-forecast-light-duty-vehicles},
  journal = {Navigant Research},
  author = {Navigant},
  year = {2017-04-18T20:30:25+00:00},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PEVP5PKU\\transportation-forecast-light-duty-vehicles.html:text/html}
}

@misc{_acea_????,
  title = {{{ACEA}} - {{European Automobile Manufacturers}}' {{Association}}},
  timestamp = {2017-06-26T09:08:34Z},
  urldate = {2017-06-26},
  url = {http://www.acea.be/statistics/tag/category/passenger-cars-world},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\T3GGZ5XQ\\passenger-cars-world.html:text/html}
}

@misc{jenkins_245_2015,
  title = {245 Million Video Surveillance Cameras Installed Globally in 2014 - {{IHS Technology}}},
  timestamp = {2017-06-26T10:12:35Z},
  urldate = {2017-06-26},
  url = {https://technology.ihs.com/532501/245-million-video-surveillance-cameras-installed-globally-in-2014},
  author = {Jenkins, Niall},
  year = {2015},
  file = {245 million video surveillance cameras installed globally in 2014 - IHS Technology:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\2DU9ZP7J\\245-million-video-surveillance-cameras-installed-globally-in-2014.html:text/html}
}

@article{koziol_world_2017,
  title = {'{{World}} First': {{Government}} Moves to Radically Overhaul {{Australia}}'s International Airports},
  shorttitle = {'{{World}} First'},
  language = {en\_US},
  timestamp = {2017-06-26T14:14:35Z},
  url = {http://www.smh.com.au/federal-politics/political-news/world-first-government-moves-to-radically-overhaul-australias-international-airports-20170116-gtss5w.html},
  journal = {The Sydney Morning Herald},
  author = {Koziol, Michael},
  month = jan,
  year = {2017},
  file = {The Sydney Morning Herald Printable:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\83KVTFP2\\world-first-government-moves-to-radically-overhaul-australias-international-airports-20170116-g.html:text/html}
}

@inproceedings{rourke_road_1990,
  title = {Road Traffic Monitoring Using Image Processing},
  abstract = {A method is described which provides data on traffic congestion over a length of roadway using inexpensive image processing and computing hardware. It provides distinct advantages over more conventional methods since data is collected over a region rather than a point in the road network. Furthermore, the state of the network can be deduced within a time scale comparable to the period with which congestion occurs on a busy road after an incident has occurred. Action can be taken on information acquired directly from the scene and not inferred from statistics built up over a period of minutes. Further work is required to take account of minor perspective distortion effects, which can cause false alarms when single vehicles occupy the distant end of the window. A measure of the amount of traffic in the window will also be needed to enable comparison with other regions of the network. Night time scenes have not been included in the test program},
  timestamp = {2017-06-26T14:57:49Z},
  booktitle = {Third {{International Conference}} on {{Road Traffic Control}}, 1990.},
  author = {Rourke, A. and Bell, M. G. H. and Hoose, N.},
  month = may,
  year = {1990},
  keywords = {computerised monitoring,computerised pattern recognition,computerised picture processing,Computer vision,data acquisition,government data processing,image processing,pattern recognition,picture processing,road traffic,roadway,traffic congestion,Traffic control},
  pages = {163--167},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\QZPCBIG5\\references.html:text/html}
}

@inproceedings{jodoin_urban_2014,
  title = {Urban {{Tracker}}: {{Multiple}} Object Tracking in Urban Mixed Traffic},
  shorttitle = {Urban {{Tracker}}},
  doi = {10.1109/WACV.2014.6836010},
  abstract = {In this paper, we study the problem of detecting and tracking multiple objects of various types in outdoor urban traffic scenes. This problem is especially challenging due to the large variation of road user appearances. To handle that variation, our system uses background subtraction to detect moving objects. In order to build the object tracks, an object model is built and updated through time inside a state machine using feature points and spatial information. When an occlusion occurs between multiple objects, the positions of feature points at previous observations are used to estimate the positions and sizes of the individual occluded objects. Our Urban Tracker algorithm is validated on four outdoor urban videos involving mixed traffic that includes pedestrians, cars, large vehicles, etc. Our method compares favorably to a current state of the art feature-based tracker for urban traffic scenes on pedestrians and mixed traffic.},
  timestamp = {2017-06-26T15:46:06Z},
  booktitle = {{{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  author = {Jodoin, J. P. and Bilodeau, G. A. and Saunier, N.},
  month = mar,
  year = {2014},
  keywords = {background subtraction,Computational modeling,feature-based tracker,Feature extraction,feature points,Image motion analysis,object detection,object model,object tracking,outdoor urban traffic scenes,outdoor urban videos,pedestrians,Roads,road traffic,road user appearance,Shape,spatial information,state machine,Tracking,traffic engineering computing,urban mixed traffic,Vehicles,Videos,video signal processing},
  pages = {885--892},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\SKII7X4V\\Jodoin et al. - 2014 - Urban Tracker Multiple object tracking in urban m.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\GK9F9ARA\\figures.html:text/html}
}

@inproceedings{shi_good_1994,
  title = {Good Features to Track},
  doi = {10.1109/CVPR.1994.323794},
  abstract = {No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments},
  timestamp = {2017-06-26T16:22:08Z},
  booktitle = {1994 {{Proceedings}} of {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Shi, Jianbo and Tomasi, C.},
  month = jun,
  year = {1994},
  keywords = {affine image transformations,Computer vision,disocclusions,feature-based,Feature extraction,feature monitoring,feature selection,Machine vision,Newton-Raphson style search methods,occlusions,performance,tracker,Tracking,vision system},
  pages = {593--600},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\M5GVMKM4\\323794.html:text/html}
}

@article{canny_computational_1986-1,
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  volume = {PAMI-8},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.1986.4767851},
  abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
  timestamp = {2017-06-26T18:10:57Z},
  number = {6},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Canny, J.},
  month = nov,
  year = {1986},
  keywords = {Detectors,edge detection,Feature extraction,Gaussian approximation,Image edge detection,image processing,Machine vision,multiscale image analysis,Performance analysis,Shape measurement,Signal synthesis,Signal to noise ratio,Uncertainty},
  pages = {679--698},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\8K7J6R2I\\4767851.html:text/html}
}

@inproceedings{harris_combined_1988,
  title = {A Combined Corner and Edge Detector},
  abstract = {Consistency of image edge filtering is of prime importance for 3D interpretation of image sequences using feature tracking algorithms. To cater for image regions containing texture and isolated features, a combined corner and edge detector based on the local auto-correlation function is utilised, and it is shown to perform with good consistency on natural imagery.},
  timestamp = {2017-06-26T18:21:56Z},
  booktitle = {In {{Proc}}. of {{Fourth Alvey Vision Conference}}},
  author = {Harris, Chris and Stephens, Mike},
  year = {1988},
  pages = {147--151},
  file = {Citeseer - Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\GEQ5T7SC\\Harris e Stephens - 1988 - A combined corner and edge detector.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\CQ5RJ39H\\summary.html:text/html}
}

@article{zadeh_fuzzy_1965,
  title = {Fuzzy Sets},
  volume = {8},
  issn = {0019-9958},
  doi = {10.1016/S0019-9958(65)90241-X},
  abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
  timestamp = {2017-06-26T18:46:11Z},
  number = {3},
  url = {http://www.sciencedirect.com/science/article/pii/S001999586590241X},
  journal = {Information and Control},
  author = {Zadeh, L. A.},
  month = jun,
  year = {1965},
  pages = {338--353},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6CV4NA4M\\Zadeh - 1965 - Fuzzy sets.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\4K5MZA59\\S001999586590241X.html:text/html}
}

@article{gottwald_early_2010,
  series = {A tribute to Ulrich H{\"o}hle on the occasion of his 65th birthday},
  title = {An Early Approach toward Graded Identity and Graded Membership in Set Theory},
  volume = {161},
  issn = {0165-0114},
  doi = {10.1016/j.fss.2009.12.005},
  abstract = {The paper considers an early approach toward a (fuzzy) set theory with a graded membership predicate and a graded equality relation which had been developed by the German mathematician Klaua in 1965. In the context of the mathematical fuzzy logic MTL of left-continuous t-norms we discuss some properties of these graded relations. We compare the simultaneous recursive definitions of these relations with the very similar approach toward Boolean algebra valued interpretations of membership and equality, presented in 1967 by Scott and R. Solovay in the context of independence proofs for ZF set theory. Finally we speculate about possible reasons why Klaua soon abandoned this approach.},
  timestamp = {2017-06-26T18:46:16Z},
  number = {18},
  url = {http://www.sciencedirect.com/science/article/pii/S0165011409005326},
  journal = {Fuzzy Sets and Systems},
  author = {Gottwald, Siegfried},
  month = sep,
  year = {2010},
  keywords = {Boolean valued universes,Fuzzy set theory,Graded identities,Mathematical fuzzy logic,Universes of fuzzy sets},
  pages = {2369--2379},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\QQIPWP6G\\Gottwald - 2010 - An early approach toward graded identity and grade.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\56B23BVS\\S0165011409005326.html:text/html}
}

@article{klaua_ansatz_1967,
  title = {Ein {{Ansatz}} Zur Mehrwertigen {{Mengenlehre}}},
  volume = {33},
  issn = {1522-2616},
  doi = {10.1002/mana.19670330503},
  language = {en},
  timestamp = {2017-06-26T18:47:57Z},
  number = {5-6},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/mana.19670330503/abstract},
  journal = {Mathematische Nachrichten},
  author = {Klaua, Dieter},
  month = jan,
  year = {1967},
  pages = {273--296},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\493AQF3S\\abstract.html:text/html}
}

@inproceedings{cock_modelling_2000,
  title = {Modelling {{Linguistic Expressions Using Fuzzy Relations}}},
  abstract = {The concept of an image of a fuzzy set under a fuzzy relation has proved to be a very powerful tool in fuzzy set theoretical applications. In this paper, we explain how it can be used to model linguistic expressions. For the representation of expressions, such as "at least middle-aged", "brighter than average", we will use fuzzy ordering relations, while resemblance relations will be suitable to model linguistic terms, such as "more or less expensive" and "very tall." We will show how these representations can be smoothly ntegrated in approximate reasoning schemes using the compositional rule of inference.},
  timestamp = {2017-06-26T19:07:45Z},
  booktitle = {In `{{Proceedings}} of the 6th {{International Conference}} on {{Soft Computing}}},
  author = {Cock, Martine De and Bodenhofer, Ulrich and Kerre, Etienne E.},
  year = {2000},
  pages = {353--360},
  file = {Citeseer - Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9MU9KJT3\\Cock et al. - 2000 - Modelling Linguistic Expressions Using Fuzzy Relat.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\J5ACH4DQ\\summary.html:text/html}
}

@article{yeh_application_2014,
  title = {Application of the {{Adaptive Neuro}}-{{Fuzzy Inference System}} for {{Optimal Design}} of {{Reinforced Concrete Beams}}},
  volume = {06},
  issn = {2150-8402, 2150-8410},
  doi = {10.4236/jilsa.2014.64013},
  timestamp = {2017-06-26T19:32:52Z},
  number = {04},
  url = {http://www.scirp.org/journal/PaperDownload.aspx?DOI=10.4236/jilsa.2014.64013},
  journal = {Journal of Intelligent Learning Systems and Applications},
  author = {Yeh, Jiin-Po and Yang, Ren-Pei},
  year = {2014},
  pages = {162--175}
}

@article{dattathreya_detection_2012,
  title = {Detection and {{Elimination}} of a {{Potential Fire}} in {{Engine}} and {{Battery Compartments}} of {{Hybrid Electric Vehicles}}},
  volume = {2012},
  issn = {1687-7101},
  doi = {10.1155/2012/687652},
  abstract = {This paper presents a novel fuzzy deterministic noncontroller type (FDNCT) system and an FDNCT inference algorithm (FIA). The FDNCT uses fuzzy inputs and produces a deterministic non-fuzzy output. The FDNCT is an extension and alternative for the existing fuzzy singleton inference algorithm. The research described in this paper applies FDNCT to build an architecture for an intelligent system to detect and to eliminate potential fires in the engine and battery compartments of a hybrid electric vehicle. The fuzzy inputs consist of sensor data from the engine and battery compartments, namely, temperature, moisture, and voltage and current of the battery. The system synthesizes the data and detects potential fires, takes actions for eliminating the hazard, and notifies the passengers about the potential fire using an audible alarm. This paper also presents the computer simulation results of the comparison between the FIA and singleton inference algorithms for detecting potential fires and determining the actions for eliminating them.},
  language = {en},
  timestamp = {2017-06-26T19:34:30Z},
  urldate = {2017-06-26},
  url = {https://www.hindawi.com/journals/afs/2012/687652/abs/},
  journal = {Advances in Fuzzy Systems},
  author = {Dattathreya, Macam S. and Singh, Harpreet and Meitzler, Thomas},
  year = {2012},
  pages = {e687652},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\UDBS4RPS\\687652.html:application/xhtml+xml;Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\WAK54NUE\\Dattathreya et al. - 2012 - Detection and Elimination of a Potential Fire in E.pdf:application/pdf}
}

@article{pal_effect_2012,
  title = {Effect of {{Road Traffic Noise Pollution}} on {{Human Work Efficiency}} in {{Government Offices}}, {{Private Organizations}}, and {{Commercial Business Centres}} in {{Agartala City Using Fuzzy Expert System}}: {{A Case Study}}},
  volume = {2012},
  issn = {1687-7101},
  shorttitle = {Effect of {{Road Traffic Noise Pollution}} on {{Human Work Efficiency}} in {{Government Offices}}, {{Private Organizations}}, and {{Commercial Business Centres}} in {{Agartala City Using Fuzzy Expert System}}},
  doi = {10.1155/2012/828593},
  abstract = {This study examines the problems of reduction of individual's efficiency in his/her respective working places because of road traffic noise pollution in Agartala due to rapidly growing vehicular traffic. This paper deals with monitoring and modeling of the disturbances caused due to vehicular road traffic interrupted by traffic flow conditions on personal work performance. Total of two hundred seventy individuals from different road side Government Offices, Private Organizations and Commercial Business Centres on both sides of busy roads of the city were interviewed for attitudinal responses. Traffic volume count and noise indices data were collected simultaneously at six selected sites of the city. A relationship was developed between different traffic noise parameters and its harmful impact on work competency of individuals using MATLAB. Regression equations developed to predict the percentage of high annoyance among the individuals are fit based on noise parameters and parameters related to traffic movements. In addition, statistical analysis was also carried out between measured and predictive values of the percentage of highly annoyed group of individuals. The present model will draw the attention of the State Government and will help the policy maker to take the necessary steps to reduce this problem.},
  language = {en},
  timestamp = {2017-06-26T19:38:10Z},
  urldate = {2017-06-26},
  url = {https://www.hindawi.com/journals/afs/2012/828593/abs/},
  journal = {Advances in Fuzzy Systems},
  author = {Pal, Debasish and Bhattacharya, Debasish},
  year = {2012},
  pages = {e828593},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\HB6HGXBP\\828593.html:application/xhtml+xml;Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\KVNFKIEH\\Pal e Bhattacharya - 2012 - Effect of Road Traffic Noise Pollution on Human Wo.pdf:application/pdf}
}

@article{gupte_detection_2002,
  title = {Detection and Classification of Vehicles},
  volume = {3},
  issn = {1524-9050},
  doi = {10.1109/6979.994794},
  abstract = {This paper presents algorithms for vision-based detection and classification of vehicles in monocular image sequences of traffic scenes recorded by a stationary camera. Processing is done at three levels: raw images, region level, and vehicle level. Vehicles are modeled as rectangular patches with certain dynamic behavior. The proposed method is based on the establishment of correspondences between regions and vehicles, as the vehicles move through the image sequence. Experimental results from highway scenes are provided which demonstrate the effectiveness of the method. We also briefly describe an interactive camera calibration tool that we have developed for recovering the camera parameters using features in the image selected by the user},
  timestamp = {2017-06-27T13:22:29Z},
  number = {1},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  author = {Gupte, S. and Masoud, O. and Martin, R. F. K. and Papanikolopoulos, N. P.},
  month = mar,
  year = {2002},
  keywords = {calibration,camera parameters,Cameras,Computer science,Computer vision,Detectors,image classification,image features,image regions,image sequence,image sequences,Intelligent transportation systems,interactive camera calibration tool,interactive systems,Layout,monocular image sequences,object detection,raw images,rectangular patches,region-vehicle correspondences,road vehicles,Traffic control,traffic engineering computing,traffic scenes,vehicle classification,vehicle detection,vehicle level image processing,Vehicles,vision-based classification,vision-based detection},
  pages = {37--47},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\WW5N5SAN\\994794.html:text/html}
}

@inproceedings{jun_tracking_2008,
  title = {Tracking and {{Segmentation}} of {{Highway Vehicles}} in {{Cluttered}} and {{Crowded Scenes}}},
  doi = {10.1109/WACV.2008.4544017},
  abstract = {Monitoring highway traffic is an important application of computer vision research. In this paper, we analyze congested highway situations where it is difficult to track individual vehicles in heavy traffic because vehicles either occlude each other or are connected together by shadow. Moreover, scenes from traffic monitoring videos are usually noisy due to weather conditions and/or video compression. We present a method that can separate occluded vehicles by tracking movements of feature points and assigning over-segmented image fragments to the motion vector that best represents the fragment's movement. Experiments were conducted on traffic videos taken from highways in Turkey, and the proposed method can successfully separate vehicles in overpopulated and cluttered scenes.},
  timestamp = {2017-06-27T14:53:57Z},
  booktitle = {2008 {{IEEE Workshop}} on {{Applications}} of {{Computer Vision}}},
  author = {Jun, G. and Aggarwal, J. K. and Gokmen, M.},
  month = jan,
  year = {2008},
  keywords = {Clustering algorithms,cluttered scenes,computerised monitoring,Computerized monitoring,Computer vision,computer vision research,congested highway situations,heavy traffic,highway traffic monitoring,highway vehicles,image segmentation,Layout,overpopulated scenes,road traffic,Road transportation,road vehicles,Tracking,traffic engineering computing,traffic monitoring videos,Turkey,vehicle detection,Video coding,video compression,Videos},
  pages = {1--6},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\SQVV562H\\Jun et al. - 2008 - Tracking and Segmentation of Highway Vehicles in C.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RR6NV92U\\4544017.html:text/html}
}

@inproceedings{buch_detection_2008,
  title = {Detection and Classification of Vehicles for Urban Traffic Scenes},
  doi = {10.1049/cp:20080305},
  abstract = {This paper presents a vehicle detection and classification system for urban traffic scenes. This aims to guide surveillance operators and reduce human resources for observing hundreds of cameras in urban traffic surveillance. We perform per frame vehicle detection and classification using 3D models. Motion silhouettes are extracted and compared to a projected model silhouette to identify the ground plane position and class of a vehicle. The system is evaluated with the reference i-LIDS dataset from the UK Home Office. Three weather conditions are tested where sunny conditions give the best classification result of 100\% outperforming overcast conditions. The full system including detection and classification for all data achieves a recall of 90.4\% at a precision of 87.9\% outperforming similar systems in the literature. The i-LIDS dataset is available to other researchers to compare with our results. We conclude with an outlook to use local features for improving the classification and detection performance.},
  timestamp = {2017-06-27T15:33:42Z},
  booktitle = {2008 5th {{International Conference}} on {{Visual Information Engineering}} ({{VIE}} 2008)},
  author = {Buch, N. and Orwell, J. and Velastin, S. A.},
  month = jul,
  year = {2008},
  keywords = {3D,Classification,Detection,Urban,Vehicle},
  pages = {182--187},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\TF876MIT\\4743413.html:text/html}
}


