
@misc{center_for_history_and_new_media_guia_????,
  title = {Guia de {{Inicia{\c c}{\~a}o R{\'a}pida}} Do {{Zotero}}},
  timestamp = {2017-06-14T00:08:37Z},
  url = {http://zotero.org/support/quick_start_guide},
  author = {{Center for History and New Media}},
  annote = {Bem-vindo ao Zotero!
Veja o Guia de Inicia{\c c}{\~a}o R{\'a}pida para aprender a recolher, gerir, citar e partilhar as suas fontes de investiga{\c c}{\~a}o.
Obrigado por instalar o Zotero.}
}

@book{shapiro_computer_2001,
  address = {Upper Saddle River, NJ},
  title = {Computer Vision},
  isbn = {978-0-13-030796-5},
  lccn = {TA1634 .S48 2001},
  timestamp = {2017-06-14T00:23:20Z},
  publisher = {{Prentice Hall}},
  author = {Shapiro, Linda G. and Stockman, George C.},
  year = {2001},
  keywords = {Computer vision},
  file = {cc-12.pdf:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\FNK4NZ23\\cc-12.pdf:application/pdf}
}

@misc{_about_????,
  title = {About {{FFmpeg}}},
  timestamp = {2017-06-14T12:18:09Z},
  urldate = {2017-06-14},
  url = {https://ffmpeg.org/about.html},
  file = {About FFmpeg:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MGWQHF79\\about.html:text/html}
}

@misc{_java_????,
  title = {Java - {{OpenCV}} ({{JavaCV}}) vs {{OpenCV}} ({{C}}/{{C}}++ Interfaces) - {{Stack Overflow}}},
  timestamp = {2017-06-14T12:19:54Z},
  urldate = {2017-06-14},
  url = {https://stackoverflow.com/questions/21207755/opencv-javacv-vs-opencv-c-c-interfaces},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\44PATV76\\opencv-javacv-vs-opencv-c-c-interfaces.html:text/html}
}

@misc{_javacpp:_2017,
  title = {Javacpp: {{The}} Missing Bridge between {{Java}} and Native {{C}}++},
  shorttitle = {Javacpp},
  timestamp = {2017-06-14T12:25:26Z},
  url = {https://github.com/bytedeco/javacpp},
  publisher = {{Bytedeco}},
  month = jun,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\38U22MA9\\javacpp.html:text/html}
}

@misc{_kinect_????,
  title = {Kinect and {{OpenNI}} \textemdash{} {{OpenCV}} 2.4.13.2 Documentation},
  timestamp = {2017-06-14T12:25:29Z},
  urldate = {2017-06-14},
  url = {http://docs.opencv.org/2.4.13.2/doc/user_guide/ug_kinect.html},
  file = {Kinect and OpenNI — OpenCV 2.4.13.2 documentation:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\J66UNKVF\\ug_kinect.html:text/html}
}

@misc{_javacpp-presets:_2017,
  title = {Javacpp-Presets: {{The}} Missing Bridge between {{Java}} and Native {{C}}++ Libraries},
  shorttitle = {Javacpp-Presets},
  timestamp = {2017-06-14T12:25:33Z},
  url = {https://github.com/bytedeco/javacpp-presets},
  publisher = {{Bytedeco}},
  month = jun,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\B9UUHMFU\\javacpp-presets.html:text/html}
}

@misc{opencv_about_2017,
  title = {About - {{OpenCV}} Library},
  timestamp = {2017-06-15T03:53:23Z},
  urldate = {2017-06-14},
  url = {http://opencv.org/about.html},
  author = {OpenCV},
  year = {2017},
  file = {About - OpenCV library:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PEKEEHPW\\about.html:text/html}
}

@misc{dahms_opencv_3_car_counting_cpp_2017,
  title = {{{OpenCV}}\_3\_{{Car}}\_{{Counting}}\_{{Cpp}}},
  timestamp = {2017-06-15T03:27:14Z},
  url = {https://github.com/MicrocontrollersAndMore/OpenCV_3_Car_Counting_Cpp},
  author = {Dahms, Chris},
  month = may,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RXBI7ZPR\\OpenCV_3_Car_Counting_Cpp.html:text/html}
}

@misc{_structural_????,
  title = {Structural {{Analysis}} and {{Shape Descriptors}} \textemdash{} {{OpenCV}} 3.0.0-Dev Documentation},
  timestamp = {2017-06-15T03:28:55Z},
  urldate = {2017-06-15},
  url = {http://docs.opencv.org/3.0-beta/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html},
  file = {Structural Analysis and Shape Descriptors — OpenCV 3.0.0-dev documentation:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PDFFP6EN\\structural_analysis_and_shape_descriptors.html:text/html}
}

@misc{dahms_contribute_2017,
  title = {Contribute to {{OpenCV}}\_3\_{{Car}}\_{{Counting}}\_{{Cpp}} Development by Creating an Account on {{GitHub}}},
  timestamp = {2017-06-15T03:57:09Z},
  url = {https://github.com/MicrocontrollersAndMore/OpenCV_3_Car_Counting_Cpp},
  author = {Dahms, Chris},
  month = may,
  year = {2017},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ZKBCEEM4\\OpenCV_3_Car_Counting_Cpp.html:text/html}
}

@misc{_blob_????,
  title = {Blob {{Detection Using OpenCV}} ( {{Python}}, {{C}}++ ) | {{Learn OpenCV}}},
  timestamp = {2017-06-16T12:52:42Z},
  urldate = {2017-06-16},
  url = {https://www.learnopencv.com/blob-detection-using-opencv-python-c/},
  file = {Blob Detection Using OpenCV ( Python, C++ ) | Learn OpenCV:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\Q6MSHU7K\\blob-detection-using-opencv-python-c.html:text/html}
}

@misc{opencv_opencv:_2017,
  title = {{{OpenCV}}: Cv::{{SimpleBlobDetector Class Reference}}},
  timestamp = {2017-06-16T12:58:38Z},
  urldate = {2017-06-16},
  url = {http://docs.opencv.org/trunk/d0/d7a/classcv_1_1SimpleBlobDetector.html},
  author = {OpenCV},
  year = {2017},
  file = {OpenCV\: cv\:\:SimpleBlobDetector Class Reference:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7DZVEGZJ\\classcv_1_1SimpleBlobDetector.html:text/html}
}

@inproceedings{badenas_applying_1998,
  title = {Applying Computer Vision Techniques to Traffic Monitoring Tasks},
  doi = {10.1007/3-540-64582-9_810},
  abstract = {This paper presents a method for tracking and segmenting vehicles in a traffic scene. The approach is based on a frame to frame segmentation followed by a tracking process. As opposed to usual segmentation methods, our method feedbacks segmentation with tracking information for improving results. Several facilities are provided for traffic monitoring such as vehicles trajectories surveillance, segmentation of vehicle shape, measuring the mean velocity of the traffic, counting the vehicles that are moving on the lanes of a road or a motorway, counting the vehicles that stop at a junction and detection of events such as a vehicle stops on a road or a possible accident.},
  language = {en},
  timestamp = {2017-06-17T20:31:26Z},
  urldate = {2017-06-17},
  url = {https://link.springer.com/chapter/10.1007/3-540-64582-9_810},
  booktitle = {Methodology and {{Tools}} in {{Knowledge}}-{{Based Systems}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Badenas, Jorge and Pla, Filiberto},
  month = jun,
  year = {1998},
  pages = {776--785},
  file = {Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\W9R2T8HX\\Badenas e Pla - 1998 - Applying computer vision techniques to traffic mon.pdf:application/pdf;Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\D5J6RFS6\\3-540-64582-9_810.html:text/html}
}

@misc{acm_ccs_2012,
  title = {{{CCS}} 2012},
  timestamp = {2017-06-18T15:02:24Z},
  urldate = {2017-06-18},
  url = {http://dl.acm.org/ccs/ccs_flat.cfm},
  author = {ACM},
  year = {2012},
  file = {CCS 2012:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\S3U3FCZE\\ccs_flat.html:text/html}
}

@misc{acm_2012_2012,
  title = {The 2012 {{ACM Computing Classification System}} \textemdash{} {{Association}} for {{Computing Machinery}}},
  timestamp = {2017-06-18T15:03:52Z},
  urldate = {2017-06-18},
  url = {http://www.acm.org/about/class/class/2012},
  author = {ACM},
  year = {2012},
  file = {The 2012 ACM Computing Classification System — Association for Computing Machinery:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7ATTAGFN\\2012.html:text/html}
}

@misc{huang_ballard_computer_vision_1996,
  title = {Ballard {{D}}. and {{Brown C}}. {{M}}. - {{Computer Vision}}},
  timestamp = {2017-06-18T15:27:04Z},
  urldate = {2017-06-18},
  url = {http://homepages.inf.ed.ac.uk/rbf/BOOKS/BANDB/Ballard__D._and_Brown__C._M.__1982__Computer_Vision.pdf},
  author = {Huang, T. S.},
  month = sep,
  year = {1996},
  file = {Ballard__D._and_Brown__C._M.__1982__Computer_Vision.pdf:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ZA2KWSFS\\Ballard__D._and_Brown__C._M.__1982__Computer_Vision.pdf:application/pdf}
}

@book{klette_computer_1998,
  title = {Computer {{Vision}}: {{Three}}-{{Dimensional Data}} from {{Images}}},
  isbn = {978-981-3083-71-4},
  shorttitle = {Computer {{Vision}}},
  abstract = {This book explores computer vision, describing the reconstruction of object surfaces and the analysis of distances between camera and objects. Fundamentals and algorithms are presented, including topics such as dynamic stereo analysis, shape from shading, photometric stereo analysis, and structural illumination. New research results in shape reconstruction and depth analysis are also included.},
  language = {en},
  timestamp = {2017-06-18T15:37:15Z},
  publisher = {{Springer Singapore}},
  author = {Klette, Reinhard and Schluns, Karsten and Koschan, Andreas},
  month = sep,
  year = {1998},
  note = {Google-Books-ID: qOJRAAAAMAAJ},
  keywords = {Computers / Computer Graphics,Computers / Computer Science,Computers / Information Technology,Computers / Optical Data Processing,Computers / Programming / General}
}

@misc{huang_computer_1996,
  title = {Computer {{Vision}} : {{Evolution And Promise}}},
  shorttitle = {Computer {{Vision}}},
  abstract = {Huang, T},
  timestamp = {2017-06-18T15:38:11Z},
  urldate = {2017-06-18},
  url = {http://cds.cern.ch/record/400313},
  journal = {CERN Document Server},
  author = {Huang, T.},
  year = {1996},
  file = {Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MCIUWN3J\\Huang - 1996 - Computer Vision  Evolution And Promise.pdf:application/pdf;Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\IZ4CBIUQ\\400313.html:text/html}
}

@article{stout_computer_1980,
  title = {Computer Vision and Robots},
  volume = {59},
  issn = {0032-9851},
  doi = {10.1049/tpe.1980.0060},
  timestamp = {2017-06-18T15:49:06Z},
  number = {4},
  journal = {Production Engineer},
  author = {Stout, K. J.},
  month = apr,
  year = {1980},
  pages = {9--},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\G4N5TECJ\\Stout - 1980 - Computer vision and robots.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\WXDAJ9X6\\4926470.html:text/html}
}

@article{l._baird_sight-i:_1978,
  title = {{{SIGHT}}-{{I}}: {{A Computer Vision System}} for {{Automated IC Chip Manufacture}}},
  volume = {8},
  issn = {0018-9472},
  shorttitle = {{{SIGHT}}-{{I}}},
  doi = {10.1109/TSMC.1978.4309913},
  timestamp = {2017-06-18T16:17:15Z},
  number = {2},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  author = {L. Baird, Michael},
  month = feb,
  year = {1978},
  keywords = {Application software,Assembly,Automatic testing,Computer aided manufacturing,Computer vision,Heat sinks,Laboratories,Manufacturing automation,Probes,Production systems},
  pages = {133--139},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\289HE2BC\\1978 - SIGHT-I A Computer Vision System for Automated IC.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\A9KDW7ZX\\4309913.html:text/html}
}

@article{binford_computer_1973-2,
  title = {Computer Vision},
  volume = {6},
  issn = {0018-9162},
  doi = {10.1109/MC.1973.6536714},
  abstract = {``Intelligent'' computers require knowledge of their environment, and the most effective means of acquiring such knowledge is by seeing. Vision opens a new realm of computer applications. Weather analysis from cloud maps and medical diagnosis from x-rays and blood cell counts are two of many high volume data processing tasks that require pictorial input. Man-machine communication will be facilitated if a person can directly show the computer a real object, rather than describe it symbolically. Designers, for example, could then easily obtain a computerized structural analysis of scale models.},
  timestamp = {2017-06-18T16:51:38Z},
  number = {5},
  journal = {Computer},
  author = {Binford, T. O. and Tenenbaum, J. M.},
  month = may,
  year = {1973},
  pages = {19--24},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\M42GBJQG\\6536714.html:text/html}
}

@inproceedings{ayache_medical_1998,
  title = {Medical Image Analysis a Challenge for Computer Vision Research},
  volume = {2},
  doi = {10.1109/ICPR.1998.711928},
  abstract = {Automating the analysis of multidimensional medical images is extremely promising to improve diagnosis and therapy quality of tomorrow's medical practice. This automation will require the solution of a number of challenging research problems, many of them being closely related to computer vision problems. The paper presents first the medical tasks that will benefit from automated medical image analysis. Then, it describes a selection of the associated research problems, with illustrations of recent results and advances},
  timestamp = {2017-06-18T16:57:26Z},
  booktitle = {Proceedings. {{Fourteenth International Conference}} on {{Pattern Recognition}} ({{Cat}}. {{No}}.{{98EX170}})},
  author = {Ayache, N.},
  month = aug,
  year = {1998},
  keywords = {Biomedical imaging,Computer vision,computer vision research,diagnosis,Image analysis,Image motion analysis,Image sequence analysis,Medical diagnostic imaging,medical image analysis,medical image processing,Medical simulation,Medical treatment,multidimensional medical images,Pathology,therapy quality,Ultrasonic imaging},
  pages = {1255--1256 vol.2},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RDWZTK6Q\\711928.html:text/html}
}

@article{buch_review_2011,
  title = {A {{Review}} of {{Computer Vision Techniques}} for the {{Analysis}} of {{Urban Traffic}}},
  volume = {12},
  issn = {1524-9050},
  doi = {10.1109/TITS.2011.2119372},
  abstract = {Automatic video analysis from urban surveillance cameras is a fast-emerging field based on computer vision techniques. We present here a comprehensive review of the state-of-the-art computer vision for traffic video with a critical analysis and an outlook to future research directions. This field is of increasing relevance for intelligent transport systems (ITSs). The decreasing hardware cost and, therefore, the increasing deployment of cameras have opened a wide application field for video analytics. Several monitoring objectives such as congestion, traffic rule violation, and vehicle interaction can be targeted using cameras that were typically originally installed for human operators. Systems for the detection and classification of vehicles on highways have successfully been using classical visual surveillance techniques such as background estimation and motion tracking for some time. The urban domain is more challenging with respect to traffic density, lower camera angles that lead to a high degree of occlusion, and the variety of road users. Methods from object categorization and 3-D modeling have inspired more advanced techniques to tackle these challenges. There is no commonly used data set or benchmark challenge, which makes the direct comparison of the proposed algorithms difficult. In addition, evaluation under challenging weather conditions (e.g., rain, fog, and darkness) would be desirable but is rarely performed. Future work should be directed toward robust combined detectors and classifiers for all road users, with a focus on realistic conditions during evaluation.},
  timestamp = {2017-06-18T17:28:30Z},
  number = {3},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  author = {Buch, N. and Velastin, S. A. and Orwell, J.},
  month = sep,
  year = {2011},
  keywords = {3D modeling,automatic video analysis,Cameras,Closed-circuit television (CCTV),Computer vision,computer vision techniques,intelligent transport systems,intersection monitoring,object categorization,Pixel,Roads,road traffic,road user counting,road users,solid modelling,Surveillance,traffic analysis,traffic information systems,traffic rule violation,urban surveillance cameras,urban traffic,urban traffic analysis,vehicle classification,vehicle detection,vehicle interaction,Vehicles,video surveillance,visual surveillance},
  pages = {920--939},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\M2M4FZK7\\Buch et al. - 2011 - A Review of Computer Vision Techniques for the Ana.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\DB5MKQPS\\5734852.html:text/html}
}

@article{dickinson_image_1984,
  title = {{{IMAGE PROCESSING APPLIED TO TRAFFIC}}, 1-{{A GENERAL REVIEW}}},
  volume = {25},
  issn = {0041-0683},
  timestamp = {2017-06-18T17:45:58Z},
  number = {1},
  urldate = {2017-06-18},
  url = {https://trid.trb.org/view.aspx?id=211436},
  journal = {Traffic Engineering \& Control},
  author = {Dickinson, K. W. and Waterfall, R. C.},
  month = jan,
  year = {1984},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\GVC6W3EE\\view.html:text/html}
}

@inproceedings{lira_computer-vision_2016,
  title = {A Computer-Vision Approach to Traffic Analysis over Intersections},
  doi = {10.1109/ITSC.2016.7795530},
  abstract = {In recent years, there has been an interest in detailed monitoring of road traffic, particularly in intersections, in order to obtain a statistical model of the flow of vehicles through them. These models aid in the optimization of traffic management and allow for smarter transportation systems. While conventional methods sensors at each of the intersections entrances/exits allow for counting, are limited in the sense that it is impossible to track a vehicle from origin to destination. A solution is presented using computer vision algorithms to footage obtained from drones floating over an intersection, in order to identify and track vehicles so that a statistical model may be extracted. This model is based on said association of an origin and a destination. The algorithm employs background subtraction and vehicle tracking with Kalman filters. The most significant challenge was how to compensate for camera movement. Based on the implementation which was developed, this the approach proved useful for tracking cars, buses, and trucks under some conditions. This paper is based upon research work done for a masters dissertation project.},
  timestamp = {2017-06-19T01:05:27Z},
  booktitle = {2016 {{IEEE}} 19th {{International Conference}} on {{Intelligent Transportation Systems}} ({{ITSC}})},
  author = {Lira, G. and Kokkinogenis, Z. and Rossetti, R. J. F. and Moura, D. C. and R{\'u}bio, T.},
  month = nov,
  year = {2016},
  keywords = {background subtraction,camera movement compensation,Cameras,computerised instrumentation,Computer vision,computer-vision approach,Feature extraction,Kalman filter,Kalman filters,master dissertation project,object tracking,optimisation,optimization,Roads,road traffic,road traffic management analysis,sensor,Sensors,smart transportation system,statistical analysis,statistical model,Tracking,Vehicles,vehicle tracking},
  pages = {47--53},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ZCA2EBNM\\Lira et al. - 2016 - A computer-vision approach to traffic analysis ove.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\SGBBPJQX\\7795530.html:text/html}
}

@inproceedings{hashmi_analysis_2012,
  title = {Analysis and Monitoring of a High Density Traffic Flow at {{T}}-Intersection Using Statistical Computer Vision Based Approach},
  doi = {10.1109/ISDA.2012.6416512},
  abstract = {A reliable traffic flow monitoring and traffic analysis approach using computer vision techniques has been proposed in this paper. The exponential increase in traffic density at urban intersections in the past few decades has raised precious and challenging demands to computer vision algorithms and technological solutions. The focus of this paper is to suggest a statistical based approach to determine the traffic parameters at heavily crowded urban intersections. The algorithm in addition to accurate tracking and counting of freeway traffic also offers high efficiency for determining vehicle count at a high traffic density T-intersection. The system uses Intel Open CV library for image processing. The implementation of algorithm is done using C++. The real time video sequence is obtained from a stationary camera placed atop a high building overlooking the particular T intersection. This paper suggests a dynamic method where each vehicle at a T intersection is passed through a number of detection zones and the final count of vehicles is derived from a statistical equation.},
  timestamp = {2017-06-19T01:08:07Z},
  booktitle = {2012 12th {{International Conference}} on {{Intelligent Systems Design}} and {{Applications}} ({{ISDA}})},
  author = {Hashmi, M. F. and Keskar, A. G.},
  month = nov,
  year = {2012},
  keywords = {Algorithm design and analysis,C++,C++ language,Computer vision,Detection zone,detection zones,freeway traffic,Heuristic algorithms,high density traffic flow analysis,high density traffic flow monitoring,image processing,image sensors,image sequences,Intel Open CV library,Monitoring,Open CV,public domain software,Real-time systems,real time video sequence,stationary camera,statistical analysis,statistical computer vision based approach,statistical equation,T-intersection,traffic engineering computing,traffic parameter determination,urban intersections,vehicle count determination,vehicle detection,Vehicles,video signal processing},
  pages = {52--57},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\RWJN76SB\\Hashmi e Keskar - 2012 - Analysis and monitoring of a high density traffic .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\BC2XVBF4\\6416512.html:text/html}
}

@inproceedings{hashmi_analysis_2012-1,
  title = {Analysis and Monitoring of a High Density Traffic Flow at {{T}}-Intersection Using Statistical Computer Vision Based Approach},
  doi = {10.1109/ISDA.2012.6416512},
  abstract = {A reliable traffic flow monitoring and traffic analysis approach using computer vision techniques has been proposed in this paper. The exponential increase in traffic density at urban intersections in the past few decades has raised precious and challenging demands to computer vision algorithms and technological solutions. The focus of this paper is to suggest a statistical based approach to determine the traffic parameters at heavily crowded urban intersections. The algorithm in addition to accurate tracking and counting of freeway traffic also offers high efficiency for determining vehicle count at a high traffic density T-intersection. The system uses Intel Open CV library for image processing. The implementation of algorithm is done using C++. The real time video sequence is obtained from a stationary camera placed atop a high building overlooking the particular T intersection. This paper suggests a dynamic method where each vehicle at a T intersection is passed through a number of detection zones and the final count of vehicles is derived from a statistical equation.},
  timestamp = {2017-06-19T01:12:02Z},
  booktitle = {2012 12th {{International Conference}} on {{Intelligent Systems Design}} and {{Applications}} ({{ISDA}})},
  author = {Hashmi, M. F. and Keskar, A. G.},
  month = nov,
  year = {2012},
  keywords = {Algorithm design and analysis,C++,C++ language,Computer vision,Detection zone,detection zones,freeway traffic,Heuristic algorithms,high density traffic flow analysis,high density traffic flow monitoring,image processing,image sensors,image sequences,Intel Open CV library,Monitoring,Open CV,public domain software,Real-time systems,real time video sequence,stationary camera,statistical analysis,statistical computer vision based approach,statistical equation,T-intersection,traffic engineering computing,traffic parameter determination,urban intersections,vehicle count determination,vehicle detection,Vehicles,video signal processing},
  pages = {52--57},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\BV5H6DQM\\Hashmi e Keskar - 2012 - Analysis and monitoring of a high density traffic .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ITN3M75X\\6416512.html:text/html}
}

@incollection{loce_traffic_2017,
  title = {Traffic {{Flow Analysis}}},
  isbn = {978-1-118-97166-6},
  abstract = {This chapter discusses traffic flow analysis in the context of technologies for intelligent transportation systems (ITS) from three important perspectives. First, we look at traffic flow from a transport engineering perspective so as to set the context in terms of the application domain. Second, we consider how flow could be observed using computer vision means and provide an overall review of relevant current research in the field. Third, we illustrate how a practical computer vision system can measure some of the variables required by traffic engineers. Last, we highlight some of the challenges posed by traffic monitoring especially in developing countries, where the density of traffic is growing at a faster rate.},
  timestamp = {2017-06-19T01:13:49Z},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7906282},
  booktitle = {Computer {{Vision}} and {{Imaging}} in {{Intelligent Transportation Systems}}},
  publisher = {{Wiley-IEEE Press}},
  author = {Loce, Robert P. and Bala, Raja and Trivedi, Mohan},
  year = {2017},
  pages = {432--},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\H29A9Z8P\\articleDetails.html:text/html},
  doi = {10.1002/9781118971666.ch6}
}

@incollection{loce_detection_2017,
  title = {Detection of {{Moving Violations}}},
  isbn = {978-1-118-97166-6},
  abstract = {Law enforcement agencies and municipalities are increasing the deployment of camera\textquestiondown\textquestiondown\textquestiondown{}based roadway monitoring systems with the goal of reducing unsafe driving behavior. While some camera\textquestiondown\textquestiondown\textquestiondown{}based systems use the acquired images and videos solely for evidentiary purposes, there is increasing use of computer vision techniques for automating the detection of violations. The most commonly monitored violations include speeding, running red lights or stop signs, wrong\textquestiondown\textquestiondown\textquestiondown{}way driving, and making illegal turns. Most traffic law enforcement applications in roadway computer vision systems involve analyzing well\textquestiondown\textquestiondown\textquestiondown{}defined and acceptable trajectories and speeds, which leads to clearly defined rules and detections. In some cases, the detections are binary, such as in red light enforcement (stopped or not). Other applications require increased accuracy and precision, such as detecting speed violations and applying a fine according to the estimated vehicle speed. There are other deployed applications where the violation involves less definitive criteria, such as reckless driving. This chapter presents various applications, giving the motivation, system requirements, methodology, and effectiveness. The more common applications of speed and stop light are described in detail, while the less common ones are briefly noted.},
  timestamp = {2017-06-19T01:13:58Z},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7906251},
  booktitle = {Computer {{Vision}} and {{Imaging}} in {{Intelligent Transportation Systems}}},
  publisher = {{Wiley-IEEE Press}},
  author = {Loce, Robert P. and Bala, Raja and Trivedi, Mohan},
  year = {2017},
  pages = {432--},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\7J7I8Q3K\\articleDetails.html:text/html},
  doi = {10.1002/9781118971666.ch5}
}

@article{buch_review_2011-1,
  title = {A {{Review}} of {{Computer Vision Techniques}} for the {{Analysis}} of {{Urban Traffic}}},
  volume = {12},
  issn = {1524-9050},
  doi = {10.1109/TITS.2011.2119372},
  abstract = {Automatic video analysis from urban surveillance cameras is a fast-emerging field based on computer vision techniques. We present here a comprehensive review of the state-of-the-art computer vision for traffic video with a critical analysis and an outlook to future research directions. This field is of increasing relevance for intelligent transport systems (ITSs). The decreasing hardware cost and, therefore, the increasing deployment of cameras have opened a wide application field for video analytics. Several monitoring objectives such as congestion, traffic rule violation, and vehicle interaction can be targeted using cameras that were typically originally installed for human operators. Systems for the detection and classification of vehicles on highways have successfully been using classical visual surveillance techniques such as background estimation and motion tracking for some time. The urban domain is more challenging with respect to traffic density, lower camera angles that lead to a high degree of occlusion, and the variety of road users. Methods from object categorization and 3-D modeling have inspired more advanced techniques to tackle these challenges. There is no commonly used data set or benchmark challenge, which makes the direct comparison of the proposed algorithms difficult. In addition, evaluation under challenging weather conditions (e.g., rain, fog, and darkness) would be desirable but is rarely performed. Future work should be directed toward robust combined detectors and classifiers for all road users, with a focus on realistic conditions during evaluation.},
  timestamp = {2017-06-19T01:14:45Z},
  number = {3},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  author = {Buch, N. and Velastin, S. A. and Orwell, J.},
  month = sep,
  year = {2011},
  keywords = {3D modeling,automatic video analysis,Cameras,Closed-circuit television (CCTV),Computer vision,computer vision techniques,intelligent transport systems,intersection monitoring,object categorization,Pixel,Roads,road traffic,road user counting,road users,solid modelling,Surveillance,traffic analysis,traffic information systems,traffic rule violation,urban surveillance cameras,urban traffic,urban traffic analysis,vehicle classification,vehicle detection,vehicle interaction,Vehicles,video surveillance,visual surveillance},
  pages = {920--939},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\W999GUNW\\Buch et al. - 2011 - A Review of Computer Vision Techniques for the Ana.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\I2ATF7Z4\\5734852.html:text/html}
}

@inproceedings{soendoro_traffic_2011,
  title = {Traffic Sign Recognition with {{Color}}-Based {{Method}}, Shape-Arc Estimation and {{SVM}}},
  doi = {10.1109/ICEEI.2011.6021584},
  abstract = {Traffic sign recognition is studied as one of the modern assistance in driving. The main purpose of it is to help driver on realizing traffic sign around the car by using computer vision enhanced to the car. In this paper, a combination method of Color-based Method and SVM is presented to do the traffic sign recognition. Color-based Method with CIELab + hue is chosen because it gives good result on localizing traffic signs. It is first used to preprocess the image to binary image. The binary image is then processed with canny to give more accurate result on detecting traffic signs. To get the traffic sign shape, the preprocessed image is checked by using Ramer-Douglas-Peucker algorithm, this algorithm will approximate each closed object shape in the preprocessed image. Detecting closed object make it unable to detect occluded and attached road signs. In order to detect occluded and attached signs, the proposed method will use two phase of detection by estimating the shape of the arc or later called the shape-arc algorithm. Approximated circle, square, or triangle images will be marked as traffic sign and processed in the recognition step with linear c-SVM. SVM classification will be based on binary images which gives 97\% accuracy. The proposed method is more accurate than methods proposed by the reference papers and the detection is able to detect harder problems such as attached signs.},
  timestamp = {2017-06-19T01:17:20Z},
  booktitle = {Proceedings of the 2011 {{International Conference}} on {{Electrical Engineering}} and {{Informatics}}},
  author = {Soendoro, D. and Supriana, I.},
  month = jul,
  year = {2011},
  keywords = {Approximation algorithms,Approximation methods,binary image,CIELab,color-based method,Computer vision,hue,Image color analysis,Image edge detection,linear c-SVM classification,Noise,object detection,object recognition,Ramer-Douglas-Peucker,Ramer-Douglas-Peucker algorithm,Shape,shape arc estimation,shape-arc estimation algorithm,support vector machines,SVM,traffic engineering computing,traffic sign detection,traffic sign recognition},
  pages = {1--6},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\VJ85P548\\Soendoro e Supriana - 2011 - Traffic sign recognition with Color-based Method, .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6MK6PEQU\\6021584.html:text/html}
}

@misc{_unsupervised_????,
  title = {An Unsupervised Approach for Traffic Sign Recognition Based on Bag-of-Visual-Words - {{IEEE Xplore Document}}},
  timestamp = {2017-06-19T02:00:49Z},
  urldate = {2017-06-19},
  url = {http://ieeexplore.ieee.org/document/7863253/},
  file = {An unsupervised approach for traffic sign recognition based on bag-of-visual-words - IEEE Xplore Document:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\C5GXJ9J7\\7863253.html:text/html}
}

@inproceedings{supriyanto_unsupervised_2016,
  title = {An Unsupervised Approach for Traffic Sign Recognition Based on Bag-of-Visual-Words},
  doi = {10.1109/ICITEED.2016.7863253},
  abstract = {There are many ideas to enhance the safety riding. Advanced Driver Assistance System (ADAS) is a system to help the driver more safety. ADAS has a purpose to assist and direct the driver in order to improve traffic safety. Traffic sign recognition is one important part of ADAS. Traffic sign is a warning sign which placed at the side or above the road to provide detail road information to the driver. In this study, we propose an unsupervised approach for traffic sign recognition based on bag-of-visual-word model. Unsupervised approach does not require label data and training process for traffic sign recognition. It helps when we have many data without label. Our experiment was conducted with dataset from German Traffic Sign Recognition Benchmark (GTSRB). It is a public dataset for traffic sign recognition. The results show that, large number of visual word enable the proposed method produce high accuracy and good quality cluster. Although the accuracy in this study is still very low. The reason for that is each image only produces 3-4 number of keypoints. Small size of the images affect the small number of keypoints.},
  timestamp = {2017-06-19T02:07:58Z},
  booktitle = {2016 8th {{International Conference}} on {{Information Technology}} and {{Electrical Engineering}} ({{ICITEE}})},
  author = {Supriyanto, C. and Luthfiarta, A. and Zeniarja, J.},
  month = oct,
  year = {2016},
  keywords = {ADAS,advanced driver assistance system,bag-of-visual-words,BoVW,driver information systems,German Traffic Sign Recognition Benchmark,GTSRB,GTSRB dataset,Hidden Markov models,Histograms,image recognition,road information,Roads,road safety,road traffic,safety riding,SURF,traffic sign recognition,unsupervised approach,unsupervised learning,Vehicles,Visualization,warning sign},
  pages = {1--4},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MAV5JQDS\\Supriyanto et al. - 2016 - An unsupervised approach for traffic sign recognit.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\NHCBTEZS\\7863253.html:text/html}
}

@inproceedings{hammoudi_self-driven_2016,
  title = {Self-Driven and Direct Spatio-Temporal Mechanisms for the Vision-Based Parking Slot Surveillance},
  doi = {10.1109/SAI.2016.7556152},
  abstract = {A vision-based and straightforward parking space surveillance system is presented. In particular, the novelty of the approach lies in the use of self-driven and direct dissimilarity computing mechanisms based on image raw brightness. Notably, the parking occupancy is estimated in real-time by applying fast computed estimators that optimize a global dissimilarity measure over slot-centered parking images. Experimental results show the operational capabilities and the efficiency of the proposed system mechanisms.},
  timestamp = {2017-06-19T02:11:02Z},
  booktitle = {2016 {{SAI Computing Conference}} ({{SAI}})},
  author = {Hammoudi, K. and Benhabiles, H. and Jandial, A. and Dornaika, F. and Mouzna, J.},
  month = jul,
  year = {2016},
  keywords = {Automobiles,Cameras,Car parking surveillance system,Computer vision,direct dissimilarity computing mechanism,direct spatio-temporal mechanism,estimation theory,global dissimilarity measure,image raw brightness,image resolution,Occupancy surveillance mechanisms,parking occupancy,parking space surveillance system,Real-time systems,road traffic,Robustness,self-driven mechanism,Sensors,slot-centered parking image,Smart car parking,Spatio-temporal parking analysis,Surveillance,traffic engineering computing,vision-based parking slot surveillance},
  pages = {1327--1329},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\ASZMQJTR\\Hammoudi et al. - 2016 - Self-driven and direct spatio-temporal mechanisms .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\IBKIU6JI\\7556152.html:text/html}
}

@incollection{loce_detection_2017-1,
  title = {Detection of {{Passenger Compartment Violations}}},
  isbn = {978-1-118-97166-6},
  abstract = {A moving violation is any violation of the law committed by the driver of a vehicle while it is in motion. Moving violations can typically be identified by observing the behavior of a vehicle such as its speed or running a stop sign or red traffic light. However, several moving violations require observation into the passenger compartment of a vehicle. Failure to wear seat belts and operating a handheld telecommunications device (i.e., cell phone) while driving are two common passenger compartment violations concerning safety. Another type of passenger compartment violation is related to efficient use of roadways. Managed lanes such as high\textquestiondown\textquestiondown\textquestiondown{}occupancy vehicle (HOV) and high\textquestiondown\textquestiondown\textquestiondown{}occupancy tolling (HOT) lanes require a minimum number of occupants within the vehicle or a tolling price that varies depending upon the number of occupants. Imaging technology and computer vision can provide automated or semiautomated enforcement of these violations. This chapter overviews existing computer vision based methods for seat belt usage, cell phone usage, and HOV/HOT lane enforcements.},
  timestamp = {2017-06-19T02:57:53Z},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7906278},
  booktitle = {Computer {{Vision}} and {{Imaging}} in {{Intelligent Transportation Systems}}},
  publisher = {{Wiley-IEEE Press}},
  author = {Loce, Robert P. and Bala, Raja and Trivedi, Mohan},
  year = {2017},
  pages = {432--},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\XC3M984M\\articleDetails.html:text/html},
  doi = {10.1002/9781118971666.ch4}
}

@misc{thapa_moving_2014,
  title = {Moving {{Object Detection}} and {{Segmentation}} Using {{Frame Differencing}} and {{Summing Technique}} - {{Semantic Scholar}}},
  abstract = {The technology of motion detection has become one of the important research areas in computer vision. In surveillance video this has got a number of applications which range from indoor and outdoor security environment, traffic control, behavior detection during spot activities and for compression of video. In this paper simple but robust moving object detection and segmentation algorithm is proposed. The algorithm is based on the background subtraction. A differencing and summing technique (DST) has been used for the moving object detection and segmentation. This method is simple and low in computational complexity as compared to traditional object identification and segmentation techniques. The experimental results show that the proposed method work efficiently in identifying and segmenting moving objects, both in indoor as well as in outdoor environment with static background.},
  timestamp = {2017-06-19T03:29:16Z},
  urldate = {2017-06-19},
  url = {/paper/Moving-Object-Detection-and-Segmentation-using-Fra-Thapa-Sharma/540de606d9a431e87aa46e88d9a1c77583a9976a},
  author = {Thapa, Gorpal and Sharma, Kalpana},
  year = {2014},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\H9KSZCCZ\\540de606d9a431e87aa46e88d9a1c77583a9976a.html:text/html}
}

@inproceedings{li_detection_2012,
  title = {Detection and Tracking of Moving Object Based on {{PTZ}} Camera},
  doi = {10.1109/ICACI.2012.6463213},
  abstract = {A new background updating algorithm of timely replacement of a central regional background was presented in this paper aiming at the PTZ camera video surveillance scenes. Before the object moving out of the setting field, the camera was static and the background subtraction algorithm was used to detect the moving object. Once the object moving out of the setting field, the camera which was controlled by the program rotates and we used the information of two images before and after the rotation to synthesize a new background for the detection of moving targets. When the target moved out of the setting field of view once again, the same method was employed to control the camera's rotation and updating the background timely. It can detect a moving object accurately and quickly and the timing controlling of the camera's rotation can realize the detection and tracking an object in a dynamic background.},
  timestamp = {2017-06-19T03:46:25Z},
  booktitle = {2012 {{IEEE Fifth International Conference}} on {{Advanced Computational Intelligence}} ({{ICACI}})},
  author = {Li, X. and Chen, Q. and Chen, H.},
  month = oct,
  year = {2012},
  keywords = {background subtraction algorithm,background updating algorithm,camera rotation control,Cameras,central regional background,Filtering algorithms,Heuristic algorithms,image sensors,image sequences,Interference,moving object detection,moving object tracking,object detection,object tracking,pan-tilt-zoom cameras,PTZ camera video surveillance scenes,static subtraction algorithm,Target tracking,video surveillance},
  pages = {493--497},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\XHXQJVWU\\Li et al. - 2012 - Detection and tracking of moving object based on P.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\Z3F3IMQR\\6463213.html:text/html}
}

@inproceedings{li_detection_2012-1,
  title = {Detection and Tracking of Moving Object Based on {{PTZ}} Camera},
  doi = {10.1109/ICACI.2012.6463213},
  abstract = {A new background updating algorithm of timely replacement of a central regional background was presented in this paper aiming at the PTZ camera video surveillance scenes. Before the object moving out of the setting field, the camera was static and the background subtraction algorithm was used to detect the moving object. Once the object moving out of the setting field, the camera which was controlled by the program rotates and we used the information of two images before and after the rotation to synthesize a new background for the detection of moving targets. When the target moved out of the setting field of view once again, the same method was employed to control the camera's rotation and updating the background timely. It can detect a moving object accurately and quickly and the timing controlling of the camera's rotation can realize the detection and tracking an object in a dynamic background.},
  timestamp = {2017-06-19T03:51:19Z},
  booktitle = {2012 {{IEEE Fifth International Conference}} on {{Advanced Computational Intelligence}} ({{ICACI}})},
  author = {Li, X. and Chen, Q. and Chen, H.},
  month = oct,
  year = {2012},
  keywords = {background subtraction algorithm,background updating algorithm,camera rotation control,Cameras,central regional background,Filtering algorithms,Heuristic algorithms,image sensors,image sequences,Interference,moving object detection,moving object tracking,object detection,object tracking,pan-tilt-zoom cameras,PTZ camera video surveillance scenes,static subtraction algorithm,Target tracking,video surveillance},
  pages = {493--497},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\QTJ4V7VI\\Li et al. - 2012 - Detection and tracking of moving object based on P.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\AZBBUH6M\\6463213.html:text/html}
}

@inproceedings{sheikh_background_2009,
  title = {Background {{Subtraction}} for {{Freely Moving Cameras}}},
  doi = {10.1109/ICCV.2009.5459334},
  abstract = {Background subtraction algorithms define the background as parts of a scene that are at rest. Traditionally, these algorithms assume a stationary camera, and identify moving objects by detecting areas in a video that change over time. In this paper, we extend the concept of `subtracting' areas at rest to apply to video captured from a freely moving camera. We do not assume that the background is well-approximated by a plane or that the camera center remains stationary during motion. The method operates entirely using 2D image measurements without requiring an explicit 3D reconstruction of the scene. A sparse model of background is built by robustly estimating a compact trajectory basis from trajectories of salient features across the video, and the background is `subtracted' by removing trajectories that lie within the space spanned by the basis. Foreground and background appearance models are then built, and an optimal pixel-wise foreground/background labeling is obtained by efficiently maximizing a posterior function.},
  timestamp = {2017-06-19T03:51:30Z},
  booktitle = {2009 {{IEEE}} 12th {{International Conference}} on {{Computer Vision}}},
  author = {Sheikh, Y. and Javed, O. and Kanade, T.},
  month = sep,
  year = {2009},
  keywords = {2D image measurement,background appearance model,background subtraction algorithm,Cameras,foreground appearance model,freely moving cameras,optimal pixel-wise background labeling,optimal pixel-wise foreground labeling,posterior function,sparse model,trajectory removal,video signal processing},
  pages = {1219--1225},
  file = {IEEE Xplore Full Text PDF:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\T7SVXQST\\Sheikh et al. - 2009 - Background Subtraction for Freely Moving Cameras.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\8T7S4I3N\\5459334.html:text/html}
}

@article{zamalieva_background_2014,
  title = {Background Subtraction for the Moving Camera: {{A}} Geometric Approach},
  volume = {127},
  issn = {1077-3142},
  shorttitle = {Background Subtraction for the Moving Camera},
  doi = {10.1016/j.cviu.2014.06.007},
  abstract = {Background subtraction is a commonly used technique in computer vision for detecting objects. While there is an extensive literature regarding background subtraction, most of the existing methods assume that the camera is stationary. This assumption limits their applicability to moving camera scenarios. In this paper, we approach the background subtraction problem from a geometric perspective to overcome this limitation. In particular, we introduce a 2.5D background model that describes the scene in terms of both its appearance and geometry. Unlike previous methods, the proposed algorithm does not rely on certain camera motions or assumptions about the scene geometry. The scene is represented as a stack of parallel hypothetical planes each of which is associated with a homography transform. A pixel that belongs to a background scene consistently maps between the consecutive frames based on its transformation with respect to the ``hypothetical plane'' it lies on. This observation disambiguates moving objects from the background. Experiments show that the proposed method, when compared to the recent literature, can successfully detect moving objects in complex scenes and with significant camera motion.},
  timestamp = {2017-06-19T03:53:48Z},
  url = {http://www.sciencedirect.com/science/article/pii/S1077314214001349},
  journal = {Computer Vision and Image Understanding},
  author = {Zamalieva, Daniya and Yilmaz, Alper},
  month = oct,
  year = {2014},
  keywords = {background subtraction,Camera motion,object detection,View geometry},
  pages = {73--85},
  file = {ScienceDirect Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\I9INGFDM\\S1077314214001349.html:text/html}
}

@misc{_background_????,
  title = {Background Subtraction Techniques: A Review - {{IEEE Xplore Document}}},
  timestamp = {2017-06-19T04:03:38Z},
  urldate = {2017-06-19},
  url = {http://ieeexplore.ieee.org/document/1400815/},
  file = {Background subtraction techniques\: a review - IEEE Xplore Document:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\VVV8TM5S\\1400815.html:text/html}
}

@inproceedings{piccardi_background_2004,
  title = {Background Subtraction Techniques: A Review},
  volume = {4},
  shorttitle = {Background Subtraction Techniques},
  doi = {10.1109/ICSMC.2004.1400815},
  abstract = {Background subtraction is a widely used approach for detecting moving objects from static cameras. Many different methods have been proposed over the recent years and both the novice and the expert can be confused about their benefits and limitations. In order to overcome this problem, this paper provides a review of the main methods and an original categorisation based on speed, memory requirements and accuracy. Such a review can effectively guide the designer to select the most suitable method for a given application in a principled way. Methods reviewed include parametric and non-parametric background density estimates and spatial correlation approaches.},
  timestamp = {2017-06-19T04:04:09Z},
  booktitle = {2004 {{IEEE International Conference}} on {{Systems}}, {{Man}} and {{Cybernetics}} ({{IEEE Cat}}. {{No}}.{{04CH37583}})},
  author = {Piccardi, M.},
  month = oct,
  year = {2004},
  keywords = {Australia,background density estimation,background subtraction technique,Cameras,Computer vision,Feature extraction,Filters,Geometry,Image motion analysis,Information technology,Layout,object detection,spatial correlation,static cameras,Subtraction techniques,Videos},
  pages = {3099--3104 vol.4},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\MUJKR3TM\\1400815.html:text/html}
}

@article{cucchiara_detecting_2003,
  title = {Detecting Moving Objects, Ghosts, and Shadows in Video Streams},
  volume = {25},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2003.1233909},
  abstract = {Background subtraction methods are widely exploited for moving object detection in videos in many applications, such as traffic monitoring, human motion capture, and video surveillance. How to correctly and efficiently model and update the background model and how to deal with shadows are two of the most distinguishing and challenging aspects of such approaches. The article proposes a general-purpose method that combines statistical assumptions with the object-level knowledge of moving objects, apparent objects (ghosts), and shadows acquired in the processing of the previous frames. Pixels belonging to moving objects, ghosts, and shadows are processed differently in order to supply an object-based selective update. The proposed approach exploits color information for both background subtraction and shadow detection to improve object segmentation and background update. The approach proves fast, flexible, and precise in terms of both pixel accuracy and reactivity to background changes.},
  timestamp = {2017-06-19T04:35:11Z},
  number = {10},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Cucchiara, R. and Grana, C. and Piccardi, M. and Prati, A.},
  month = oct,
  year = {2003},
  keywords = {apparent objects,Application software,background modeling,background subtraction methods,background update,color information,color segmentation,ghosts,human motion capture,Image motion analysis,image segmentation,Layout,Monitoring,moving object detection,object-based selective update,object detection,object-level knowledge,object segmentation,pixel processing,shadow detection,Shape,statistical assumptions,Streaming media,Traffic control,traffic monitoring,US Department of Transportation,video streams,video surveillance},
  pages = {1337--1342},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9QNFSRMP\\1233909.html:text/html}
}

@inproceedings{lo_automatic_2001,
  title = {Automatic Congestion Detection System for Underground Platforms},
  doi = {10.1109/ISIMP.2001.925356},
  abstract = {An automatic monitoring system is proposed in this paper for detecting overcrowding conditions in the platforms of underground train services. Whenever overcrowding is detected, the system will notify the station operators to take appropriate actions to prevent accidents, such as people falling off or being pushed onto the tracks. The system is designed to use existing closed circuit television (CCTV) cameras for acquiring images of the platforms. In order to focus on the passengers on the platform, background subtraction and update techniques are used. In addition, due to the high variation of brightness on the platforms, a variance filter is introduced to optimize the removal of background pixels. A multi-layer feed forward neural network was developed for classifying the levels of congestion. The system was tested with recorded video from the London Bridge station, and the testing results were shown to be accurate in identifying overcrowding conditions for the unique platform environment},
  timestamp = {2017-06-19T04:51:25Z},
  booktitle = {Proceedings of 2001 {{International Symposium}} on {{Intelligent Multimedia}}, {{Video}} and {{Speech Processing}}. {{ISIMP}} 2001 ({{IEEE Cat}}. {{No}}.{{01EX489}})},
  author = {Lo, B. P. L. and Velastin, S. A.},
  year = {2001},
  keywords = {Accidents,automatic monitoring,Brightness,Cameras,Circuits,closed circuit television,Computerized monitoring,Condition monitoring,congestion detection system,feedforward neural nets,Feeds,Filters,image processing,Monitoring,multi-layer feed forward neural network,railways,System testing,TV,underground platforms,underground train services,variance filter,variation of brightness},
  pages = {158--161},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\6ZMWB9UE\\925356.html:text/html}
}

@inproceedings{lo_automatic_2001-1,
  title = {Automatic Congestion Detection System for Underground Platforms},
  doi = {10.1109/ISIMP.2001.925356},
  abstract = {An automatic monitoring system is proposed in this paper for detecting overcrowding conditions in the platforms of underground train services. Whenever overcrowding is detected, the system will notify the station operators to take appropriate actions to prevent accidents, such as people falling off or being pushed onto the tracks. The system is designed to use existing closed circuit television (CCTV) cameras for acquiring images of the platforms. In order to focus on the passengers on the platform, background subtraction and update techniques are used. In addition, due to the high variation of brightness on the platforms, a variance filter is introduced to optimize the removal of background pixels. A multi-layer feed forward neural network was developed for classifying the levels of congestion. The system was tested with recorded video from the London Bridge station, and the testing results were shown to be accurate in identifying overcrowding conditions for the unique platform environment},
  timestamp = {2017-06-19T04:52:41Z},
  booktitle = {Proceedings of 2001 {{International Symposium}} on {{Intelligent Multimedia}}, {{Video}} and {{Speech Processing}}. {{ISIMP}} 2001 ({{IEEE Cat}}. {{No}}.{{01EX489}})},
  author = {Lo, B. P. L. and Velastin, S. A.},
  year = {2001},
  keywords = {Accidents,automatic monitoring,Brightness,Cameras,Circuits,closed circuit television,Computerized monitoring,Condition monitoring,congestion detection system,feedforward neural nets,Feeds,Filters,image processing,Monitoring,multi-layer feed forward neural network,railways,System testing,TV,underground platforms,underground train services,variance filter,variation of brightness},
  pages = {158--161},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\JMBQXC9J\\925356.html:text/html}
}

@inproceedings{zivkovic_improved_2004,
  title = {Improved Adaptive {{Gaussian}} Mixture Model for Background Subtraction},
  volume = {2},
  doi = {10.1109/ICPR.2004.1333992},
  abstract = {Background subtraction is a common computer vision task. We analyze the usual pixel-level approach. We develop an efficient adaptive algorithm using Gaussian mixture probability density. Recursive equations are used to constantly update the parameters and but also to simultaneously select the appropriate number of components for each pixel.},
  timestamp = {2017-06-19T05:56:20Z},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Pattern Recognition}}, 2004. {{ICPR}} 2004.},
  author = {Zivkovic, Z.},
  month = aug,
  year = {2004},
  keywords = {Adaptive algorithm,adaptive Gaussian mixture model,background subtraction,Cameras,Computer vision,Density functional theory,Equations,Gaussian processes,Intelligent systems,Layout,object detection,Pixel,pixel-level approach,probability density,recursive equations,recursive functions,Surveillance},
  pages = {28--31 Vol.2},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\PA4JGQNU\\1333992.html:text/html}
}

@incollection{suetens_model-based_1991,
  title = {Model-{{Based Image Segmentation}}: {{Methods}} and {{Applications}}},
  shorttitle = {Model-{{Based Image Segmentation}}},
  abstract = {We discuss different methods and applications of model-based segmentation of medical images. In this paper model-based segmentation is defined as the assignment of labels to pixels or voxels by matching the a priori known object model to the image data. Labels may have probabilities expressing their uncertainty. Particularly we compare optimization methods with the knowledge-based system approach.},
  language = {en},
  timestamp = {2017-06-19T06:01:05Z},
  urldate = {2017-06-19},
  url = {https://link.springer.com/chapter/10.1007/978-3-642-48650-0_1},
  booktitle = {{{AIME}} 91},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Suetens, P. and Verbeeck, R. and Delaere, D. and Nuyts, J. and Bijnens, B.},
  year = {1991},
  pages = {3--24},
  file = {Snapshot:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\HJ8QZBS3\\978-3-642-48650-0_1.html:text/html},
  doi = {10.1007/978-3-642-48650-0_1}
}

@inproceedings{fong_edge_2004,
  title = {Edge Model Based Segmentation},
  volume = {3},
  doi = {10.1109/ICPR.2004.1334605},
  abstract = {Segmentation is an important operation in image analysis. It is employed to extract interested objects from an image under test. Much research work has been performed and the optimal graph theoretic approach to data clustering is one of the promising methods. However, when the image size is large, the graph size is very large. As a result the graph becomes complex and its processing is computation demanding. In this paper, we propose to simplify the problem by pre-segmenting the image under test using an edge model before applying the optimal graph theoretic approach to data clustering. The experimental results show that the proposed method can efficiently segments an image with satisfactory results.},
  timestamp = {2017-06-19T06:13:45Z},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Pattern Recognition}}, 2004. {{ICPR}} 2004.},
  author = {Fong, Chi-Keung and Cham, Wai-Keun},
  month = aug,
  year = {2004},
  keywords = {data clustering,Data mining,edge detection,edge model,graph theory,Humans,Image analysis,Image edge detection,image processing,Image representation,image segmentation,Image texture analysis,object extraction,optimal graph theoretic method,optimisation,Partitioning algorithms,pattern clustering,Testing,Video coding},
  pages = {618--621 Vol.3},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\U89M3RB2\\1334605.html:text/html}
}

@misc{_model-based_????,
  title = {Model-Based Segmentation of the Brain from 3-{{D MRI}} Using Active Surfaces - {{IEEE Xplore Document}}},
  timestamp = {2017-06-19T06:16:13Z},
  urldate = {2017-06-19},
  url = {http://ieeexplore.ieee.org/document/404372/},
  file = {Model-based segmentation of the brain from 3-D MRI using active surfaces - IEEE Xplore Document:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9HCHE3H7\\404372.html:text/html}
}

@inproceedings{snell_model-based_1993,
  title = {Model-Based Segmentation of the Brain from 3-{{D MRI}} Using Active Surfaces},
  doi = {10.1109/NEBC.1993.404372},
  abstract = {Traditional segmentation approaches have proven inadequate when faced with the anatomical complexity and variability exhibited by biological structures such as the brain. A 3-D extension to the 'snakes' algorithm has been implemented and used to segment the brain surface from MRI image volumes of the head in an effort to investigate model-based, top-down segmentation strategies. These active surfaces allow closed surfaces of complex objects to be recovered using a priori knowledge in the form of initial conditions and applied external forces. Preliminary results suggest that active surfaces may be initialized according to a preconceived model and adaptively deformed by image data to recover the desired object surface},
  timestamp = {2017-06-19T06:16:18Z},
  booktitle = {1993 {{IEEE Annual Northeast Bioengineering Conference}}},
  author = {Snell, J. W. and Merickel, M. B. and Goble, J. C. and Brookeman, J. B. and Kassell, N. F.},
  month = mar,
  year = {1993},
  keywords = {3-D MRI,Active contours,active surfaces,adaptively deformed,Biomedical engineering,Biomedical imaging,biomedical NMR,Boundary conditions,Brain modeling,brain models,closed surfaces,complex objects,Computer vision,edge detection,energy minimisation,image data,image segmentation,Magnetic resonance imaging,medical image processing,model-based segmentation,Radiology,snakes algorithm,top-down segmentation strategies,Topology},
  pages = {164--165},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\JoaoNeto\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\y422qjyz.default\\zotero\\storage\\9BTZVXUR\\404372.html:text/html}
}


